{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/amohammadi/GNN_venv/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Link Prediction using Graph Neural Networks\n",
    "\n",
    "\"\"\"\n",
    "import dgl\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import itertools\n",
    "import numpy as np\n",
    "import scipy.sparse as sp\n",
    "import dgl.data\n",
    "import pandas as pd\n",
    "from dgl import graph\n",
    "from dgl.nn import SAGEConv\n",
    "import dgl.function as fn\n",
    "import math\n",
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Closest / Working"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import dgl\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import itertools\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from dgl import graph\n",
    "from dgl.nn import SAGEConv\n",
    "import dgl.function as fn\n",
    "import math\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "# Check if GPU is available\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Build a two-layer GraphSAGE model\n",
    "class GraphSAGE(nn.Module):\n",
    "    def __init__(self, in_feats, h_feats):\n",
    "        super(GraphSAGE, self).__init__()\n",
    "        self.conv1 = SAGEConv(in_feats, h_feats, 'mean')\n",
    "        self.conv2 = SAGEConv(h_feats, h_feats, 'mean')\n",
    "\n",
    "    def forward(self, g, in_feat):\n",
    "        h = self.conv1(g, in_feat)\n",
    "        h = F.relu(h)\n",
    "        h = self.conv2(g, h)\n",
    "        return h\n",
    "\n",
    "class DotPredictor(nn.Module):\n",
    "    def forward(self, g, h):\n",
    "        with g.local_scope():\n",
    "            g.ndata['h'] = h\n",
    "            g.apply_edges(fn.u_dot_v('h', 'h', 'score'))\n",
    "            return g.edata['score'][:, 0]\n",
    "\n",
    "class MLPPredictor(nn.Module):\n",
    "    def __init__(self, h_feats):\n",
    "        super().__init__()\n",
    "        self.W1 = nn.Linear(h_feats * 2, h_feats)\n",
    "        self.W2 = nn.Linear(h_feats, 1)\n",
    "\n",
    "    def apply_edges(self, edges):\n",
    "        h = torch.cat([edges.src['h'], edges.dst['h']], 1)\n",
    "        return {'score': self.W2(F.relu(self.W1(h))).squeeze(1)}\n",
    "\n",
    "    def forward(self, g, h):\n",
    "        with g.local_scope():\n",
    "            g.ndata['h'] = h\n",
    "            g.apply_edges(self.apply_edges)\n",
    "            return g.edata['score']\n",
    "\n",
    "def compute_loss(pos_score, neg_score):\n",
    "    scores = torch.cat([pos_score, neg_score])\n",
    "    labels = torch.cat([torch.ones(pos_score.shape[0]), torch.zeros(neg_score.shape[0])]).to(device)\n",
    "    return F.binary_cross_entropy_with_logits(scores, labels)\n",
    "\n",
    "def compute_auc(pos_score, neg_score):\n",
    "    scores = torch.cat([pos_score, neg_score]).numpy()\n",
    "    labels = torch.cat([torch.ones(pos_score.shape[0]), torch.zeros(neg_score.shape[0])]).numpy()\n",
    "    return roc_auc_score(labels, scores)\n",
    "\n",
    "def compute_acc(pos_score, neg_score):\n",
    "    scores = torch.cat([pos_score, neg_score]).cpu().numpy()\n",
    "    scores = [1 if i >= 0.5 else 0 for i in scores]\n",
    "    labels = torch.cat([torch.ones(pos_score.shape[0]), torch.zeros(neg_score.shape[0])]).cpu().numpy()\n",
    "    correct_pred = 0\n",
    "    for i in range(labels.shape[0]):\n",
    "        if labels[i] == scores[i]:\n",
    "            correct_pred += 1\n",
    "    return correct_pred / labels.shape[0]\n",
    "\n",
    "\n",
    "\n",
    "datasets = ['algo004', 'ml', 'comp', 'virtualshakespeare']\n",
    "for ds in datasets:\n",
    "    data_total = pd.read_csv('data/w_removal_%s' % ds, sep=\" \", header=None)\n",
    "    print('Analyzing %s Dataset' % ds)\n",
    "    data_total.columns = [\"n1\", \"n2\", \"f1\", \"f2\", \"f3\", \"f4\", \"f5\", \"f6\", \"f7\", \"l\"]\n",
    "    data_total.dropna(subset=['n1', 'n2'], inplace=True)\n",
    "\n",
    "    # taking the unique values of the nodes and saving the indices\n",
    "    nodes = np.unique(data_total[['n1', 'n2']].values)\n",
    "    node_index = {node: idx for idx, node in enumerate(nodes)}\n",
    "\n",
    "    # creating an adj matrix (numpy) of size nodes*nodes filled with 0s\n",
    "    adj_matrix = np.zeros((len(nodes), len(nodes)), dtype=float)\n",
    "\n",
    "    # populating the adj matrix using the nodes and the labels\n",
    "    for _, row in data_total.iterrows():\n",
    "        i, j = node_index[row['n1']], node_index[row['n2']]\n",
    "        adj_matrix[i, j] = row['l']\n",
    "        adj_matrix[j, i] = row['l']\n",
    "\n",
    "    # turning the numpy matrix into a pandas df\n",
    "    adj_df = pd.DataFrame(adj_matrix, index=nodes, columns=nodes)\n",
    "\n",
    "    labels = data_total[\"l\"]\n",
    "    ones_label = np.where(labels == 1)\n",
    "\n",
    "    # Create graph using node indices\n",
    "    src = data_total[\"n1\"].map(node_index).astype(int)\n",
    "    dst = data_total[\"n2\"].map(node_index).astype(int)\n",
    "\n",
    "    src = torch.tensor(src.values[ones_label], dtype=torch.int64).to(device)\n",
    "    dst = torch.tensor(dst.values[ones_label], dtype=torch.int64).to(device)\n",
    "\n",
    "    \"\"\"g = dgl.graph((src, dst))\n",
    "\n",
    "    # Initialize node features as an identity matrix\n",
    "    inputs = torch.eye(g.number_of_nodes()).to(device)\"\"\"\n",
    "\n",
    "    g = graph((torch.cat([src, dst]), torch.cat([dst, src])))\n",
    "    g = g.to(device)\n",
    "    inputs = g.adj().to_dense().to(device)    \n",
    "\n",
    "    \"\"\"\n",
    "    Generate all of the possible edges and remove 90% of them from the training set\n",
    "    \"\"\"\n",
    "    upper_tri_idx = np.triu_indices_from(adj_df, k=1)\n",
    "    pairs = [(i, j) for i, j in zip(*upper_tri_idx)]\n",
    "    pairs += [(j, i) for i, j in pairs]  # Add (j, i) for each (i, j)\n",
    "    \n",
    "    np.random.shuffle(pairs)\n",
    "    possible_edges = np.array(pairs)\n",
    "    \n",
    "    test_size = int(len(possible_edges) * 0.05)\n",
    "    train_size = len(possible_edges) - test_size\n",
    "    \n",
    "    test_edges = possible_edges[:test_size]\n",
    "    train_edges = possible_edges[test_size:]\n",
    "\n",
    "    test_pos_u = []\n",
    "    test_pos_v = []\n",
    "    test_neg_u = []\n",
    "    test_neg_v = []\n",
    "\n",
    "    for u, v in test_edges:\n",
    "        if g.has_edges_between(u, v):\n",
    "            test_pos_u.append(u)\n",
    "            test_pos_v.append(v)\n",
    "        else:\n",
    "            test_neg_u.append(u)\n",
    "            test_neg_v.append(v)\n",
    "\n",
    "    train_pos_u = []\n",
    "    train_pos_v = []\n",
    "    train_neg_u = []\n",
    "    train_neg_v = []\n",
    "    \n",
    "    for u, v in train_edges:\n",
    "        if g.has_edges_between(u, v):\n",
    "            train_pos_u.append(u)\n",
    "            train_pos_v.append(v)\n",
    "        else:\n",
    "            train_neg_u.append(u)\n",
    "            train_neg_v.append(v)\n",
    "            \n",
    "    #train_u, train_v = train_edges[:, 0], train_edges[:, 1]\n",
    "\n",
    "    # Create subgraphs for training and testing\n",
    "    train_pos_g = dgl.graph((torch.tensor(train_pos_u), torch.tensor(train_pos_v)), num_nodes=g.number_of_nodes()).to(device)\n",
    "    train_neg_g = dgl.graph((torch.tensor(train_neg_u), torch.tensor(train_neg_v)), num_nodes=g.number_of_nodes()).to(device)\n",
    "\n",
    "    test_pos_g = dgl.graph((torch.tensor(test_pos_u), torch.tensor(test_pos_v)), num_nodes=g.number_of_nodes()).to(device)\n",
    "    test_neg_g = dgl.graph((torch.tensor(test_neg_u), torch.tensor(test_neg_v)), num_nodes=g.number_of_nodes()).to(device)\n",
    "\n",
    "    print(f'Number of nodes and edges in train_pos_g: {len(train_pos_g.nodes())} , {len(train_pos_g.edges()[0])}')\n",
    "    print(f'Number of nodes and edges in train_neg_g: {len(train_neg_g.nodes())} , {len(train_neg_g.edges()[0])}')\n",
    "    print(f'Number of nodes and edges in test_pos_g: {len(test_pos_g.nodes())} , {len(test_pos_g.edges()[0])}')\n",
    "    print(f'Number of nodes and edges in test_neg_g: {len(test_neg_g.nodes())} , {len(test_neg_g.edges()[0])}')\n",
    "    \n",
    "    model = GraphSAGE(g.number_of_nodes(), 16).to(device)\n",
    "    pred = DotPredictor().to(device)\n",
    "\n",
    "    optimizer = torch.optim.Adam(itertools.chain(model.parameters(), pred.parameters()), lr=0.001)\n",
    "\n",
    "    for e in range(501):\n",
    "        h = model(train_pos_g, inputs)\n",
    "        pos_score = pred(train_pos_g, h)\n",
    "        neg_score = pred(train_neg_g, h)\n",
    "        loss = compute_loss(pos_score, neg_score)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if e % 100 == 0:\n",
    "            print('In epoch {}, loss: {}'.format(e, loss.item()))\n",
    "\n",
    "    with torch.no_grad():\n",
    "        h = model(train_pos_g, inputs)\n",
    "        pos_score = pred(test_pos_g, h)\n",
    "        neg_score = pred(test_neg_g, h)\n",
    "        print('AUC', compute_auc(pos_score, neg_score))\n",
    "        print('ACC', compute_acc(pos_score, neg_score))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# With loop for percentage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/amohammadi/GNN_venv/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analyzing algo004 Dataset\n",
      "Test size: 0.05\n",
      "Number of nodes and edges in train_pos_g: 1165 , 12857\n",
      "Number of nodes and edges in train_neg_g: 1165 , 1275400\n",
      "Number of nodes and edges in test_pos_g: 1165 , 689\n",
      "Number of nodes and edges in test_neg_g: 1165 , 67114\n",
      "In epoch 0, loss: 1.1400586366653442\n",
      "In epoch 100, loss: 0.6855957508087158\n",
      "In epoch 200, loss: 0.6709774136543274\n",
      "In epoch 300, loss: 0.6522641181945801\n",
      "In epoch 400, loss: 0.6355752348899841\n",
      "In epoch 500, loss: 0.6226822733879089\n",
      "AUC 0.7750189191338888\n",
      "ACC 0.9841452443107237\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'auc' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 203\u001b[0m\n\u001b[1;32m    192\u001b[0m             \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAUC\u001b[39m\u001b[38;5;124m'\u001b[39m, compute_auc(pos_score, neg_score))\n\u001b[1;32m    193\u001b[0m             \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mACC\u001b[39m\u001b[38;5;124m'\u001b[39m, compute_acc(pos_score, neg_score))\n\u001b[1;32m    196\u001b[0m         results\u001b[38;5;241m.\u001b[39mappend({\n\u001b[1;32m    197\u001b[0m             \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDataset\u001b[39m\u001b[38;5;124m'\u001b[39m: ds,\n\u001b[1;32m    198\u001b[0m             \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTest_Size\u001b[39m\u001b[38;5;124m'\u001b[39m: test_size,\n\u001b[1;32m    199\u001b[0m             \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTrain_Pos_Edges\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;28mlen\u001b[39m(train_pos_g\u001b[38;5;241m.\u001b[39medges()[\u001b[38;5;241m0\u001b[39m]),\n\u001b[1;32m    200\u001b[0m             \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTrain_Neg_Edges\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;28mlen\u001b[39m(train_neg_g\u001b[38;5;241m.\u001b[39medges()[\u001b[38;5;241m0\u001b[39m]),\n\u001b[1;32m    201\u001b[0m             \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTest_Pos_Edges\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;28mlen\u001b[39m(test_pos_g\u001b[38;5;241m.\u001b[39medges()[\u001b[38;5;241m0\u001b[39m]),\n\u001b[1;32m    202\u001b[0m             \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTest_Neg_Edges\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;28mlen\u001b[39m(test_neg_g\u001b[38;5;241m.\u001b[39medges()[\u001b[38;5;241m0\u001b[39m]),\n\u001b[0;32m--> 203\u001b[0m             \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAUC\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[43mauc\u001b[49m,\n\u001b[1;32m    204\u001b[0m             \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mACC\u001b[39m\u001b[38;5;124m'\u001b[39m: acc\n\u001b[1;32m    205\u001b[0m         })\n\u001b[1;32m    207\u001b[0m \u001b[38;5;66;03m# Convert results to DataFrame\u001b[39;00m\n\u001b[1;32m    208\u001b[0m results_df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(results)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'auc' is not defined"
     ]
    }
   ],
   "source": [
    "import dgl\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import itertools\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from dgl import graph\n",
    "from dgl.nn import SAGEConv\n",
    "import dgl.function as fn\n",
    "import math\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "# Check if GPU is available\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Build a two-layer GraphSAGE model\n",
    "class GraphSAGE(nn.Module):\n",
    "    def __init__(self, in_feats, h_feats):\n",
    "        super(GraphSAGE, self).__init__()\n",
    "        self.conv1 = SAGEConv(in_feats, h_feats, 'mean')\n",
    "        self.conv2 = SAGEConv(h_feats, h_feats, 'mean')\n",
    "\n",
    "    def forward(self, g, in_feat):\n",
    "        h = self.conv1(g, in_feat)\n",
    "        h = F.relu(h)\n",
    "        h = self.conv2(g, h)\n",
    "        return h\n",
    "\n",
    "class DotPredictor(nn.Module):\n",
    "    def forward(self, g, h):\n",
    "        with g.local_scope():\n",
    "            g.ndata['h'] = h\n",
    "            g.apply_edges(fn.u_dot_v('h', 'h', 'score'))\n",
    "            return g.edata['score'][:, 0]\n",
    "\n",
    "class MLPPredictor(nn.Module):\n",
    "    def __init__(self, h_feats):\n",
    "        super().__init__()\n",
    "        self.W1 = nn.Linear(h_feats * 2, h_feats)\n",
    "        self.W2 = nn.Linear(h_feats, 1)\n",
    "\n",
    "    def apply_edges(self, edges):\n",
    "        h = torch.cat([edges.src['h'], edges.dst['h']], 1)\n",
    "        return {'score': self.W2(F.relu(self.W1(h))).squeeze(1)}\n",
    "\n",
    "    def forward(self, g, h):\n",
    "        with g.local_scope():\n",
    "            g.ndata['h'] = h\n",
    "            g.apply_edges(self.apply_edges)\n",
    "            return g.edata['score']\n",
    "\n",
    "def compute_loss(pos_score, neg_score):\n",
    "    scores = torch.cat([pos_score, neg_score])\n",
    "    labels = torch.cat([torch.ones(pos_score.shape[0]), torch.zeros(neg_score.shape[0])]).to(device)\n",
    "    return F.binary_cross_entropy_with_logits(scores, labels)\n",
    "\n",
    "def compute_auc(pos_score, neg_score):\n",
    "    scores = torch.cat([pos_score, neg_score]).numpy()\n",
    "    labels = torch.cat([torch.ones(pos_score.shape[0]), torch.zeros(neg_score.shape[0])]).numpy()\n",
    "    return roc_auc_score(labels, scores)\n",
    "\n",
    "def compute_acc(pos_score, neg_score):\n",
    "    scores = torch.cat([pos_score, neg_score]).cpu().numpy()\n",
    "    scores = [1 if i >= 0.5 else 0 for i in scores]\n",
    "    labels = torch.cat([torch.ones(pos_score.shape[0]), torch.zeros(neg_score.shape[0])]).cpu().numpy()\n",
    "    correct_pred = 0\n",
    "    for i in range(labels.shape[0]):\n",
    "        if labels[i] == scores[i]:\n",
    "            correct_pred += 1\n",
    "    return correct_pred / labels.shape[0]\n",
    "\n",
    "results = []\n",
    "\n",
    "datasets = ['algo004', 'ml', 'comp', 'virtualshakespeare']\n",
    "test_sizes = [0.05, 0.1, 0.15, 0.2, 0.25]\n",
    "\n",
    "for ds in datasets:\n",
    "    data_total = pd.read_csv('data/w_removal_%s' % ds, sep=\" \", header=None)\n",
    "    print('Analyzing %s Dataset' % ds)\n",
    "    data_total.columns = [\"n1\", \"n2\", \"f1\", \"f2\", \"f3\", \"f4\", \"f5\", \"f6\", \"f7\", \"l\"]\n",
    "    data_total.dropna(subset=['n1', 'n2'], inplace=True)\n",
    "\n",
    "    # taking the unique values of the nodes and saving the indices\n",
    "    nodes = np.unique(data_total[['n1', 'n2']].values)\n",
    "    node_index = {node: idx for idx, node in enumerate(nodes)}\n",
    "\n",
    "    # creating an adj matrix (numpy) of size nodes*nodes filled with 0s\n",
    "    adj_matrix = np.zeros((len(nodes), len(nodes)), dtype=float)\n",
    "\n",
    "    # populating the adj matrix using the nodes and the labels\n",
    "    for _, row in data_total.iterrows():\n",
    "        i, j = node_index[row['n1']], node_index[row['n2']]\n",
    "        adj_matrix[i, j] = row['l']\n",
    "        adj_matrix[j, i] = row['l']\n",
    "\n",
    "    # turning the numpy matrix into a pandas df\n",
    "    adj_df = pd.DataFrame(adj_matrix, index=nodes, columns=nodes)\n",
    "\n",
    "    labels = data_total[\"l\"]\n",
    "    ones_label = np.where(labels == 1)\n",
    "\n",
    "    # Create graph using node indices\n",
    "    src = data_total[\"n1\"].map(node_index).astype(int)\n",
    "    dst = data_total[\"n2\"].map(node_index).astype(int)\n",
    "\n",
    "    src = torch.tensor(src.values[ones_label], dtype=torch.int64).to(device)\n",
    "    dst = torch.tensor(dst.values[ones_label], dtype=torch.int64).to(device)\n",
    "\n",
    "    g = graph((torch.cat([src, dst]), torch.cat([dst, src])))\n",
    "    g = g.to(device)\n",
    "    inputs = g.adj().to_dense().to(device)    \n",
    "\n",
    "    for test_size in test_sizes:\n",
    "        print(f'Test size: {test_size}')\n",
    "        \"\"\"\n",
    "        Generate all of the possible edges and remove 90% of them from the training set\n",
    "        \"\"\"\n",
    "        upper_tri_idx = np.triu_indices_from(adj_df, k=1)\n",
    "        pairs = [(i, j) for i, j in zip(*upper_tri_idx)]\n",
    "        pairs += [(j, i) for i, j in pairs]  # Add (j, i) for each (i, j)\n",
    "        \n",
    "        np.random.shuffle(pairs)\n",
    "        possible_edges = np.array(pairs)\n",
    "        \n",
    "        test_size = int(len(possible_edges) * test_size)\n",
    "        train_size = len(possible_edges) - test_size\n",
    "        \n",
    "        test_edges = possible_edges[:test_size]\n",
    "        train_edges = possible_edges[test_size:]\n",
    "\n",
    "        test_pos_u = []\n",
    "        test_pos_v = []\n",
    "        test_neg_u = []\n",
    "        test_neg_v = []\n",
    "\n",
    "        for u, v in test_edges:\n",
    "            if g.has_edges_between(u, v):\n",
    "                test_pos_u.append(u)\n",
    "                test_pos_v.append(v)\n",
    "            else:\n",
    "                test_neg_u.append(u)\n",
    "                test_neg_v.append(v)\n",
    "\n",
    "        train_pos_u = []\n",
    "        train_pos_v = []\n",
    "        train_neg_u = []\n",
    "        train_neg_v = []\n",
    "        \n",
    "        for u, v in train_edges:\n",
    "            if g.has_edges_between(u, v):\n",
    "                train_pos_u.append(u)\n",
    "                train_pos_v.append(v)\n",
    "            else:\n",
    "                train_neg_u.append(u)\n",
    "                train_neg_v.append(v)\n",
    "                \n",
    "        # Create subgraphs for training and testing\n",
    "        train_pos_g = dgl.graph((torch.tensor(train_pos_u), torch.tensor(train_pos_v)), num_nodes=g.number_of_nodes()).to(device)\n",
    "        train_neg_g = dgl.graph((torch.tensor(train_neg_u), torch.tensor(train_neg_v)), num_nodes=g.number_of_nodes()).to(device)\n",
    "\n",
    "        test_pos_g = dgl.graph((torch.tensor(test_pos_u), torch.tensor(test_pos_v)), num_nodes=g.number_of_nodes()).to(device)\n",
    "        test_neg_g = dgl.graph((torch.tensor(test_neg_u), torch.tensor(test_neg_v)), num_nodes=g.number_of_nodes()).to(device)\n",
    "\n",
    "        print(f'Number of nodes and edges in train_pos_g: {len(train_pos_g.nodes())} , {len(train_pos_g.edges()[0])}')\n",
    "        print(f'Number of nodes and edges in train_neg_g: {len(train_neg_g.nodes())} , {len(train_neg_g.edges()[0])}')\n",
    "        print(f'Number of nodes and edges in test_pos_g: {len(test_pos_g.nodes())} , {len(test_pos_g.edges()[0])}')\n",
    "        print(f'Number of nodes and edges in test_neg_g: {len(test_neg_g.nodes())} , {len(test_neg_g.edges()[0])}')\n",
    "        \n",
    "        model = GraphSAGE(g.number_of_nodes(), 16).to(device)\n",
    "        pred = DotPredictor().to(device)\n",
    "\n",
    "        optimizer = torch.optim.Adam(itertools.chain(model.parameters(), pred.parameters()), lr=0.001)\n",
    "\n",
    "        for e in range(501):\n",
    "            h = model(train_pos_g, inputs)\n",
    "            pos_score = pred(train_pos_g, h)\n",
    "            neg_score = pred(train_neg_g, h)\n",
    "            loss = compute_loss(pos_score, neg_score)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            if e % 100 == 0:\n",
    "                print('In epoch {}, loss: {}'.format(e, loss.item()))\n",
    "\n",
    "        with torch.no_grad():\n",
    "            h = model(train_pos_g, inputs)\n",
    "            pos_score = pred(test_pos_g, h)\n",
    "            neg_score = pred(test_neg_g, h)\n",
    "            print('AUC', compute_auc(pos_score, neg_score))\n",
    "            print('ACC', compute_acc(pos_score, neg_score))\n",
    "\n",
    "        \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating the 4 graphs for algo004 and comp datasets then combining"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/amohammadi/GNN_venv/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import dgl\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import itertools\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from dgl import graph\n",
    "from dgl.nn import SAGEConv\n",
    "import dgl.function as fn\n",
    "import math\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import networkx as nx\n",
    "import os\n",
    "from joblib import Parallel, delayed\n",
    "\n",
    "\n",
    "# Build a two-layer GraphSAGE model\n",
    "class GraphSAGE(nn.Module):\n",
    "    def __init__(self, in_feats, h_feats):\n",
    "        super(GraphSAGE, self).__init__()\n",
    "        self.conv1 = SAGEConv(in_feats, h_feats, 'mean')\n",
    "        self.conv2 = SAGEConv(h_feats, h_feats, 'mean')\n",
    "\n",
    "    def forward(self, g, in_feat):\n",
    "        h = self.conv1(g, in_feat)\n",
    "        h = F.relu(h)\n",
    "        h = self.conv2(g, h)\n",
    "        return h\n",
    "\n",
    "class DotPredictor(nn.Module):\n",
    "    def forward(self, g, h):\n",
    "        with g.local_scope():\n",
    "            g.ndata['h'] = h\n",
    "            g.apply_edges(fn.u_dot_v('h', 'h', 'score'))\n",
    "            return g.edata['score'][:, 0]\n",
    "\n",
    "class MLPPredictor(nn.Module):\n",
    "    def __init__(self, h_feats):\n",
    "        super().__init__()\n",
    "        self.W1 = nn.Linear(h_feats * 2, h_feats)\n",
    "        self.W2 = nn.Linear(h_feats, 1)\n",
    "\n",
    "    def apply_edges(self, edges):\n",
    "        h = torch.cat([edges.src['h'], edges.dst['h']], 1)\n",
    "        return {'score': self.W2(F.relu(self.W1(h))).squeeze(1)}\n",
    "\n",
    "    def forward(self, g, h):\n",
    "        with g.local_scope():\n",
    "            g.ndata['h'] = h\n",
    "            g.apply_edges(self.apply_edges)\n",
    "            return g.edata['score']\n",
    "\n",
    "def compute_loss(pos_score, neg_score):\n",
    "    scores = torch.cat([pos_score, neg_score])\n",
    "    labels = torch.cat([torch.ones(pos_score.shape[0]), torch.zeros(neg_score.shape[0])])\n",
    "    return F.binary_cross_entropy_with_logits(scores, labels)\n",
    "\n",
    "def compute_auc(pos_score, neg_score):\n",
    "    scores = torch.cat([pos_score, neg_score]).cpu().numpy()\n",
    "    labels = torch.cat([torch.ones(pos_score.shape[0]), torch.zeros(neg_score.shape[0])]).cpu().numpy()\n",
    "    return roc_auc_score(labels, scores)\n",
    "\n",
    "def compute_acc(pos_score, neg_score):\n",
    "    scores = torch.cat([pos_score, neg_score]).cpu().numpy()\n",
    "    scores = [1 if i >= 0.5 else 0 for i in scores]\n",
    "    labels = torch.cat([torch.ones(pos_score.shape[0]), torch.zeros(neg_score.shape[0])]).cpu().numpy()\n",
    "    correct_pred = 0\n",
    "    for i in range(labels.shape[0]):\n",
    "        if labels[i] == scores[i]:\n",
    "            correct_pred += 1\n",
    "    return correct_pred / labels.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_algebraic_connectivity(nx_graph):\n",
    "    # Get all connected components in the graph\n",
    "    connected_components = [nx_graph.subgraph(c).copy() for c in nx.connected_components(nx_graph)]\n",
    "\n",
    "    # Initialize list to store algebraic connectivity values\n",
    "    connectivity_values = []\n",
    "\n",
    "    # Loop through each connected component and calculate the algebraic connectivity\n",
    "    for component in connected_components:\n",
    "        if len(component) >= 5:  # Algebraic connectivity is only defined for graphs with more than 1 node\n",
    "            connectivity = nx.algebraic_connectivity(component)\n",
    "            connectivity_values.append(connectivity)\n",
    "        else:\n",
    "            print(f\"Component with only 1 node: {list(component.nodes)}\")\n",
    "\n",
    "    # Calculate and return the mean algebraic connectivity\n",
    "    if connectivity_values:\n",
    "        mean_connectivity = sum(connectivity_values) / len(connectivity_values)\n",
    "        return mean_connectivity\n",
    "    else:\n",
    "        return 0.0  # Return 0 if there are no valid connected components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Component with only 1 node: [6]\n",
      "Component with only 1 node: [19]\n",
      "Component with only 1 node: [32, 787]\n",
      "Component with only 1 node: [35]\n",
      "Component with only 1 node: [528, 39, 654, 183]\n",
      "Component with only 1 node: [42, 238]\n",
      "Component with only 1 node: [45]\n",
      "Component with only 1 node: [51]\n",
      "Component with only 1 node: [249, 67, 598]\n",
      "Component with only 1 node: [74]\n",
      "Component with only 1 node: [83]\n",
      "Component with only 1 node: [592, 101, 439]\n",
      "Component with only 1 node: [106]\n",
      "Component with only 1 node: [112, 969]\n",
      "Component with only 1 node: [118]\n",
      "Component with only 1 node: [126, 758]\n",
      "Component with only 1 node: [128, 1070]\n",
      "Component with only 1 node: [134]\n",
      "Component with only 1 node: [144]\n",
      "Component with only 1 node: [157]\n",
      "Component with only 1 node: [173]\n",
      "Component with only 1 node: [346, 885, 309, 182]\n",
      "Component with only 1 node: [189]\n",
      "Component with only 1 node: [1092, 199]\n",
      "Component with only 1 node: [216]\n",
      "Component with only 1 node: [226, 949]\n",
      "Component with only 1 node: [227]\n",
      "Component with only 1 node: [228]\n",
      "Component with only 1 node: [234]\n",
      "Component with only 1 node: [252]\n",
      "Component with only 1 node: [253]\n",
      "Component with only 1 node: [282]\n",
      "Component with only 1 node: [287]\n",
      "Component with only 1 node: [306]\n",
      "Component with only 1 node: [307]\n",
      "Component with only 1 node: [330]\n",
      "Component with only 1 node: [331, 853]\n",
      "Component with only 1 node: [345, 1150]\n",
      "Component with only 1 node: [360]\n",
      "Component with only 1 node: [372]\n",
      "Component with only 1 node: [373, 445]\n",
      "Component with only 1 node: [375]\n",
      "Component with only 1 node: [377]\n",
      "Component with only 1 node: [384]\n",
      "Component with only 1 node: [387]\n",
      "Component with only 1 node: [399]\n",
      "Component with only 1 node: [405]\n",
      "Component with only 1 node: [407]\n",
      "Component with only 1 node: [536, 433, 614]\n",
      "Component with only 1 node: [434]\n",
      "Component with only 1 node: [476]\n",
      "Component with only 1 node: [489]\n",
      "Component with only 1 node: [510]\n",
      "Component with only 1 node: [931, 532]\n",
      "Component with only 1 node: [768, 534]\n",
      "Component with only 1 node: [552]\n",
      "Component with only 1 node: [573]\n",
      "Component with only 1 node: [581]\n",
      "Component with only 1 node: [587]\n",
      "Component with only 1 node: [616]\n",
      "Component with only 1 node: [639]\n",
      "Component with only 1 node: [992, 653]\n",
      "Component with only 1 node: [663]\n",
      "Component with only 1 node: [682]\n",
      "Component with only 1 node: [683]\n",
      "Component with only 1 node: [693]\n",
      "Component with only 1 node: [696]\n",
      "Component with only 1 node: [698]\n",
      "Component with only 1 node: [703]\n",
      "Component with only 1 node: [734]\n",
      "Component with only 1 node: [743]\n",
      "Component with only 1 node: [750]\n",
      "Component with only 1 node: [757]\n",
      "Component with only 1 node: [792, 848]\n",
      "Component with only 1 node: [799]\n",
      "Component with only 1 node: [801]\n",
      "Component with only 1 node: [812]\n",
      "Component with only 1 node: [818]\n",
      "Component with only 1 node: [826]\n",
      "Component with only 1 node: [830]\n",
      "Component with only 1 node: [833]\n",
      "Component with only 1 node: [835]\n",
      "Component with only 1 node: [846]\n",
      "Component with only 1 node: [872]\n",
      "Component with only 1 node: [892]\n",
      "Component with only 1 node: [899]\n",
      "Component with only 1 node: [901]\n",
      "Component with only 1 node: [914]\n",
      "Component with only 1 node: [924]\n",
      "Component with only 1 node: [948]\n",
      "Component with only 1 node: [958]\n",
      "Component with only 1 node: [963]\n",
      "Component with only 1 node: [1016]\n",
      "Component with only 1 node: [1057]\n",
      "Component with only 1 node: [1074]\n",
      "Component with only 1 node: [1075]\n",
      "Component with only 1 node: [1082]\n",
      "Component with only 1 node: [1086]\n",
      "Component with only 1 node: [1117]\n",
      "Component with only 1 node: [1126]\n",
      "Component with only 1 node: [1143]\n",
      "Component with only 1 node: [1153]\n",
      "Component with only 1 node: [1158]\n",
      "Component with only 1 node: [1160]\n",
      "Component with only 1 node: [1161]\n",
      "Component with only 1 node: [1162]\n"
     ]
    }
   ],
   "source": [
    "G = nx.from_numpy_array(adj_matrix)\n",
    "fiedler = mean_algebraic_connectivity(G)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2650309698583493"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fiedler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20\n",
      "87\n"
     ]
    }
   ],
   "source": [
    "connected_components = [G.subgraph(c).copy() for c in nx.connected_components(G)]\n",
    "temp = 0\n",
    "temp2 = 0\n",
    "for component in connected_components:\n",
    "        if len(component) > 1:  # Algebraic connectivity is only defined for graphs with more than 1 node\n",
    "            temp += 1\n",
    "        else:\n",
    "            temp2 += 1\n",
    "print(temp)\n",
    "print(temp2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Algo004 dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analyzing algo004 Dataset\n",
      "Fold 1 of 10\n",
      "In epoch 0, loss: 1.2714616060256958\n",
      "In epoch 100, loss: 0.6884055733680725\n",
      "In epoch 200, loss: 0.676465630531311\n",
      "In epoch 300, loss: 0.6645388007164001\n",
      "In epoch 400, loss: 0.655613362789154\n",
      "In epoch 500, loss: 0.6438919305801392\n",
      "AUC 0.7595192411201703\n",
      "ACC 0.9855463622553574\n",
      "Fold 2 of 10\n",
      "In epoch 0, loss: 1.6992290019989014\n",
      "In epoch 100, loss: 0.6865578889846802\n",
      "In epoch 200, loss: 0.6731442213058472\n",
      "In epoch 300, loss: 0.6601445078849792\n",
      "In epoch 400, loss: 0.6496444344520569\n",
      "In epoch 500, loss: 0.639138400554657\n",
      "AUC 0.7457902577990463\n",
      "ACC 0.9843930209577747\n",
      "Fold 3 of 10\n",
      "In epoch 0, loss: 1.246417760848999\n",
      "In epoch 100, loss: 0.688645601272583\n",
      "In epoch 200, loss: 0.6716256141662598\n",
      "In epoch 300, loss: 0.6524522304534912\n",
      "In epoch 400, loss: 0.6404491662979126\n",
      "In epoch 500, loss: 0.6289765238761902\n",
      "AUC 0.7900909152602864\n",
      "ACC 0.9845110098373229\n",
      "Fold 4 of 10\n",
      "In epoch 0, loss: 1.652479887008667\n",
      "In epoch 100, loss: 0.6915237307548523\n",
      "In epoch 200, loss: 0.680076003074646\n",
      "In epoch 300, loss: 0.6580348014831543\n",
      "In epoch 400, loss: 0.637627899646759\n",
      "In epoch 500, loss: 0.6270461082458496\n",
      "AUC 0.7837136835960845\n",
      "ACC 0.9849741161895491\n",
      "Fold 5 of 10\n",
      "In epoch 0, loss: 2.1688477993011475\n",
      "In epoch 100, loss: 0.6957759261131287\n",
      "In epoch 200, loss: 0.671891987323761\n",
      "In epoch 300, loss: 0.6493182182312012\n",
      "In epoch 400, loss: 0.6351412534713745\n",
      "In epoch 500, loss: 0.6263436675071716\n",
      "AUC 0.7436523343119076\n",
      "ACC 0.9855729097532557\n",
      "Fold 6 of 10\n",
      "In epoch 0, loss: 2.1487157344818115\n",
      "In epoch 100, loss: 0.698198139667511\n",
      "In epoch 200, loss: 0.6895006895065308\n",
      "In epoch 300, loss: 0.6833398342132568\n",
      "In epoch 400, loss: 0.6710668206214905\n",
      "In epoch 500, loss: 0.6588459610939026\n",
      "AUC 0.8056265461041294\n",
      "ACC 0.9828326180257511\n",
      "Fold 7 of 10\n",
      "In epoch 0, loss: 1.239295244216919\n",
      "In epoch 100, loss: 0.6862784624099731\n",
      "In epoch 200, loss: 0.666662871837616\n",
      "In epoch 300, loss: 0.6367398500442505\n",
      "In epoch 400, loss: 0.6167668104171753\n",
      "In epoch 500, loss: 0.6048604846000671\n",
      "AUC 0.7595591407795516\n",
      "ACC 0.9869209327020928\n",
      "Fold 8 of 10\n",
      "In epoch 0, loss: 1.38693106174469\n",
      "In epoch 100, loss: 0.679664134979248\n",
      "In epoch 200, loss: 0.6588087677955627\n",
      "In epoch 300, loss: 0.6440250873565674\n",
      "In epoch 400, loss: 0.6336655020713806\n",
      "In epoch 500, loss: 0.6245034337043762\n",
      "AUC 0.7905591504570835\n",
      "ACC 0.9872925976726693\n",
      "Fold 9 of 10\n",
      "In epoch 0, loss: 1.6228500604629517\n",
      "In epoch 100, loss: 0.6842489242553711\n",
      "In epoch 200, loss: 0.6548930406570435\n",
      "In epoch 300, loss: 0.6352664232254028\n",
      "In epoch 400, loss: 0.6227343082427979\n",
      "In epoch 500, loss: 0.6156274676322937\n",
      "AUC 0.7204565466668642\n",
      "ACC 0.9877586537468843\n",
      "Fold 10 of 10\n",
      "In epoch 0, loss: 1.0505249500274658\n",
      "In epoch 100, loss: 0.6841477155685425\n",
      "In epoch 200, loss: 0.6598358750343323\n",
      "In epoch 300, loss: 0.6392353177070618\n",
      "In epoch 400, loss: 0.624399721622467\n",
      "In epoch 500, loss: 0.6127216219902039\n",
      "AUC 0.7658045456240635\n",
      "ACC 0.9862012005368495\n",
      "Results for algo004 dataset\n",
      "AUC mean: 0.7664772361719188\n",
      "AUC std: 0.02476058431643213\n",
      "ACC mean: 0.9856003421677505\n",
      "ACC std: 0.0014257425926906295\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 600x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "res = []\n",
    "datasets = ['algo004']\n",
    "for ds in datasets:\n",
    "    data_total = pd.read_csv('data/w_removal_%s' % ds, sep=\" \", header=None)\n",
    "    print('Analyzing %s Dataset' % ds)\n",
    "    data_total.columns = [\"n1\", \"n2\", \"f1\", \"f2\", \"f3\", \"f4\", \"f5\", \"f6\", \"f7\", \"l\"]\n",
    "    data_total.dropna(subset=['n1', 'n2'], inplace=True)\n",
    "\n",
    "    # taking the unique values of the nodes and saving the indices\n",
    "    nodes = np.unique(data_total[['n1', 'n2']].values)\n",
    "    node_index = {node: idx for idx, node in enumerate(nodes)}\n",
    "\n",
    "    # creating an adj matrix (numpy) of size nodes*nodes filled with 0s\n",
    "    adj_matrix = np.zeros((len(nodes), len(nodes)), dtype=float)\n",
    "\n",
    "    # populating the adj matrix using the nodes and the labels\n",
    "    for _, row in data_total.iterrows():\n",
    "        i, j = node_index[row['n1']], node_index[row['n2']]\n",
    "        adj_matrix[i, j] = row['l']\n",
    "        adj_matrix[j, i] = row['l']\n",
    "\n",
    "    # turning the numpy matrix into a pandas df\n",
    "    adj_df = pd.DataFrame(adj_matrix, index=nodes, columns=nodes)\n",
    "\n",
    "    labels = data_total[\"l\"]\n",
    "    ones_label = np.where(labels == 1)\n",
    "\n",
    "    # Create graph using node indices\n",
    "    src = data_total[\"n1\"].map(node_index).astype(int)\n",
    "    dst = data_total[\"n2\"].map(node_index).astype(int)\n",
    "\n",
    "    src = torch.tensor(src.values[ones_label], dtype=torch.int64)\n",
    "    dst = torch.tensor(dst.values[ones_label], dtype=torch.int64)\n",
    "\n",
    "    \"\"\"g = dgl.graph((src, dst))\n",
    "\n",
    "    # Initialize node features as an identity matrix\n",
    "    inputs = torch.eye(g.number_of_nodes()).to(device)\"\"\"\n",
    "\n",
    "    algo_g = graph((torch.cat([src, dst]), torch.cat([dst, src])))\n",
    "    algo_g = algo_g\n",
    "    inputs_algo = algo_g.adj().to_dense()\n",
    "    \n",
    "\n",
    "    \"\"\"\n",
    "    Generate all of the possible edges and remove 90% of them from the training set\n",
    "    \"\"\"\n",
    "    # K-fold cross validation\n",
    "    k = 10\n",
    "    auc_all = np.zeros((k,))\n",
    "    acc_all = np.zeros((k,))\n",
    "\n",
    "    for _ in range(k):\n",
    "        print('Fold %d of %d' % (_+1, k))\n",
    "    \n",
    "        \n",
    "        upper_tri_idx = np.triu_indices_from(adj_df, k=1)\n",
    "        pairs = [(i, j) for i, j in zip(*upper_tri_idx)]\n",
    "        pairs += [(j, i) for i, j in pairs]  # Add (j, i) for each (i, j)\n",
    "        \n",
    "        np.random.shuffle(pairs)\n",
    "        possible_edges = np.array(pairs)\n",
    "        \n",
    "        test_size = int(len(possible_edges) * 0.25) # How much of the possible edges we will be removing\n",
    "        train_size = len(possible_edges) - test_size\n",
    "        \n",
    "        test_edges = possible_edges[:test_size]\n",
    "        train_edges = possible_edges[test_size:]\n",
    "    \n",
    "        test_pos_u = []\n",
    "        test_pos_v = []\n",
    "        test_neg_u = []\n",
    "        test_neg_v = []\n",
    "    \n",
    "        for u, v in test_edges:\n",
    "            if algo_g.has_edges_between(u, v):\n",
    "                test_pos_u.append(u)\n",
    "                test_pos_v.append(v)\n",
    "            else:\n",
    "                test_neg_u.append(u)\n",
    "                test_neg_v.append(v)\n",
    "    \n",
    "        train_pos_u = []\n",
    "        train_pos_v = []\n",
    "        train_neg_u = []\n",
    "        train_neg_v = []\n",
    "        \n",
    "        for u, v in train_edges:\n",
    "            if algo_g.has_edges_between(u, v):\n",
    "                train_pos_u.append(u)\n",
    "                train_pos_v.append(v)\n",
    "            else:\n",
    "                train_neg_u.append(u)\n",
    "                train_neg_v.append(v)\n",
    "                \n",
    "        #train_u, train_v = train_edges[:, 0], train_edges[:, 1]\n",
    "    \n",
    "        # Create subgraphs for training and testing\n",
    "        train_pos_g_algo = dgl.graph((torch.tensor(train_pos_u), torch.tensor(train_pos_v)), num_nodes=algo_g.number_of_nodes())\n",
    "        train_neg_g_algo = dgl.graph((torch.tensor(train_neg_u), torch.tensor(train_neg_v)), num_nodes=algo_g.number_of_nodes())\n",
    "    \n",
    "        test_pos_g_algo = dgl.graph((torch.tensor(test_pos_u), torch.tensor(test_pos_v)), num_nodes=algo_g.number_of_nodes())\n",
    "        test_neg_g_algo = dgl.graph((torch.tensor(test_neg_u), torch.tensor(test_neg_v)), num_nodes=algo_g.number_of_nodes())\n",
    "        \n",
    "         \n",
    "        model = GraphSAGE(algo_g.number_of_nodes(), 16)\n",
    "        pred = DotPredictor()\n",
    "        \n",
    "        optimizer = torch.optim.Adam(itertools.chain(model.parameters(), pred.parameters()), lr=0.001)\n",
    "        \n",
    "        for e in range(501):\n",
    "            h = model(train_pos_g_algo, inputs_algo)\n",
    "            pos_score = pred(train_pos_g_algo, h)\n",
    "            neg_score = pred(train_neg_g_algo, h)\n",
    "            loss = compute_loss(pos_score, neg_score)\n",
    "        \n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        \n",
    "            if e % 100 == 0:\n",
    "                print('In epoch {}, loss: {}'.format(e, loss.item()))\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            h = model(train_pos_g_algo, inputs_algo)\n",
    "            pos_score = pred(test_pos_g_algo, h)\n",
    "            neg_score = pred(test_neg_g_algo, h)\n",
    "            auc = compute_auc(pos_score, neg_score)\n",
    "            acc = compute_acc(pos_score, neg_score)\n",
    "            print('AUC', auc)\n",
    "            print('ACC', acc)\n",
    "    \n",
    "            auc_all[_] = compute_auc(pos_score, neg_score)\n",
    "            acc_all[_] = compute_acc(pos_score, neg_score)\n",
    "    \n",
    "            res.append({\n",
    "            'Dataset': ds,\n",
    "            'Test_Size': test_size,\n",
    "            'AUC': auc,\n",
    "            'ACC': acc\n",
    "        })\n",
    "        \n",
    "torch.save({\n",
    "    'model_state_dict': model.state_dict(),\n",
    "    'optimizer_state_dict': optimizer.state_dict(),\n",
    "    'epoch': e\n",
    "}, 'model_algo_25p.pth')\n",
    "\n",
    "dgl.save_graphs(\"graphs_algo_25p.bin\", [train_pos_g_algo, train_neg_g_algo, test_pos_g_algo, test_neg_g_algo, algo_g])\n",
    "\n",
    "res.append({\n",
    "    'AUC mean': str(np.mean(auc_all)),\n",
    "    'AUC std': str(np.std(auc_all)),\n",
    "    'ACC mean': str(np.mean(acc_all)),\n",
    "    'ACC std': str(np.std(acc_all))\n",
    "})\n",
    "\n",
    "G = nx.from_numpy_array(adj_matrix)\n",
    "fiedler = nx.algebraic_connectivity(G)\n",
    "\n",
    "res.append({'Algebraic_Connectivity': fiedler})\n",
    "# Convert results to DataFrame\n",
    "results_df = pd.DataFrame(res)\n",
    "\n",
    "# Save to CSV\n",
    "results_df.to_csv('Algo004_25p.csv', index=False)\n",
    "        \n",
    "# print results\n",
    "print('Results for %s dataset' % ds)\n",
    "print('AUC mean: ' + str(np.mean(auc_all)))\n",
    "print('AUC std: ' + str(np.std(auc_all)))\n",
    "\n",
    "print('ACC mean: ' + str(np.mean(acc_all)))\n",
    "print('ACC std: ' + str(np.std(acc_all)))\n",
    "\n",
    "# Generate true labels\n",
    "y_true_pos = [1] * len(pos_score)  # True labels for positive edges (1)\n",
    "y_true_neg = [0] * len(neg_score)  # True labels for negative edges (0)\n",
    "\n",
    "y_true = y_true_pos + y_true_neg  # Combine true labels for the test set\n",
    "\n",
    "# Generate predicted labels by thresholding the scores\n",
    "y_pred_pos = (pos_score >= 0.5).int().tolist()  # Predicted labels for positive edges\n",
    "y_pred_neg = (neg_score >= 0.5).int().tolist()  # Predicted labels for negative edges\n",
    "\n",
    "y_pred = y_pred_pos + y_pred_neg  # Combine predicted labels for the test set\n",
    "\n",
    "# Compute confusion matrix\n",
    "cm = confusion_matrix(y_true, y_pred)\n",
    "\n",
    "# Visualize the confusion matrix using seaborn with integer formatting\n",
    "plt.figure(figsize=(6, 6))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', cbar=False, \n",
    "            xticklabels=['Predicted 0', 'Predicted 1'],\n",
    "            yticklabels=['Actual 0', 'Actual 1'])\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.savefig('confusion_matrix_algo25p.png', dpi=200, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "np.save('cm_algo_25.npy', cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of nodes and edges in train_pos_g_algo: 1165 , 12899\n",
      "Number of nodes and edges in train_neg_g_algo: 1165 , 1275358\n",
      "Number of nodes and edges in test_pos_g_algo: 1165 , 647\n",
      "Number of nodes and edges in test_neg_g_algo: 1165 , 67156\n"
     ]
    }
   ],
   "source": [
    "print(f'Number of nodes and edges in train_pos_g_algo: {len(train_pos_g_algo.nodes())} , {len(train_pos_g_algo.edges()[0])}')\n",
    "print(f'Number of nodes and edges in train_neg_g_algo: {len(train_neg_g_algo.nodes())} , {len(train_neg_g_algo.edges()[0])}')\n",
    "print(f'Number of nodes and edges in test_pos_g_algo: {len(test_pos_g_algo.nodes())} , {len(test_pos_g_algo.edges()[0])}')\n",
    "print(f'Number of nodes and edges in test_neg_g_algo: {len(test_neg_g_algo.nodes())} , {len(test_neg_g_algo.edges()[0])}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comp dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analyzing comp Dataset\n",
      "Fold 1 of 10\n",
      "In epoch 0, loss: 11.502903938293457\n",
      "In epoch 100, loss: 0.7309852838516235\n",
      "In epoch 200, loss: 0.701102614402771\n",
      "In epoch 300, loss: 0.696399986743927\n",
      "In epoch 400, loss: 0.6945177912712097\n",
      "In epoch 500, loss: 0.69322270154953\n",
      "AUC 0.711071639752211\n",
      "ACC 0.9856185885551848\n",
      "Fold 2 of 10\n",
      "In epoch 0, loss: 6.448144435882568\n",
      "In epoch 100, loss: 0.7061193585395813\n",
      "In epoch 200, loss: 0.6950445175170898\n",
      "In epoch 300, loss: 0.6928181648254395\n",
      "In epoch 400, loss: 0.6916407346725464\n",
      "In epoch 500, loss: 0.6900569796562195\n",
      "AUC 0.686015762576065\n",
      "ACC 0.988174514893091\n",
      "Fold 3 of 10\n",
      "In epoch 0, loss: 6.552830696105957\n",
      "In epoch 100, loss: 0.7201206684112549\n",
      "In epoch 200, loss: 0.6987108588218689\n",
      "In epoch 300, loss: 0.6948665976524353\n",
      "In epoch 400, loss: 0.6938846111297607\n",
      "In epoch 500, loss: 0.6932128071784973\n",
      "AUC 0.6736897999494926\n",
      "ACC 0.9896279817080706\n",
      "Fold 4 of 10\n",
      "In epoch 0, loss: 4.296034812927246\n",
      "In epoch 100, loss: 0.702731728553772\n",
      "In epoch 200, loss: 0.6953257918357849\n",
      "In epoch 300, loss: 0.6936383843421936\n",
      "In epoch 400, loss: 0.6925395727157593\n",
      "In epoch 500, loss: 0.6914590001106262\n",
      "AUC 0.6581021593899787\n",
      "ACC 0.9882783339513039\n",
      "Fold 5 of 10\n",
      "In epoch 0, loss: 13.99251651763916\n",
      "In epoch 100, loss: 0.7253192663192749\n",
      "In epoch 200, loss: 0.7016093730926514\n",
      "In epoch 300, loss: 0.6954820156097412\n",
      "In epoch 400, loss: 0.6938928961753845\n",
      "In epoch 500, loss: 0.6932589411735535\n",
      "AUC 0.6506171904994409\n",
      "ACC 0.9882832777159807\n",
      "Fold 6 of 10\n",
      "In epoch 0, loss: 9.652738571166992\n",
      "In epoch 100, loss: 0.7143635153770447\n",
      "In epoch 200, loss: 0.697475254535675\n",
      "In epoch 300, loss: 0.6946405172348022\n",
      "In epoch 400, loss: 0.6937983632087708\n",
      "In epoch 500, loss: 0.6934426426887512\n",
      "AUC 0.6487884942222459\n",
      "ACC 0.9906958348782597\n",
      "Fold 7 of 10\n",
      "In epoch 0, loss: 5.052729606628418\n",
      "In epoch 100, loss: 0.7030150890350342\n",
      "In epoch 200, loss: 0.6944642066955566\n",
      "In epoch 300, loss: 0.6932865977287292\n",
      "In epoch 400, loss: 0.6919972896575928\n",
      "In epoch 500, loss: 0.6902020573616028\n",
      "AUC 0.6776012542367993\n",
      "ACC 0.9867655419602027\n",
      "Fold 8 of 10\n",
      "In epoch 0, loss: 10.08476448059082\n",
      "In epoch 100, loss: 0.7064263820648193\n",
      "In epoch 200, loss: 0.6961497068405151\n",
      "In epoch 300, loss: 0.694441020488739\n",
      "In epoch 400, loss: 0.6936596632003784\n",
      "In epoch 500, loss: 0.6931429505348206\n",
      "AUC 0.6894298701711985\n",
      "ACC 0.9872698059572365\n",
      "Fold 9 of 10\n",
      "In epoch 0, loss: 7.289157390594482\n",
      "In epoch 100, loss: 0.7058436870574951\n",
      "In epoch 200, loss: 0.6963245868682861\n",
      "In epoch 300, loss: 0.6938836574554443\n",
      "In epoch 400, loss: 0.6924015879631042\n",
      "In epoch 500, loss: 0.6911599040031433\n",
      "AUC 0.6514799158126882\n",
      "ACC 0.9876257570139662\n",
      "Fold 10 of 10\n",
      "In epoch 0, loss: 9.069377899169922\n",
      "In epoch 100, loss: 0.7032018899917603\n",
      "In epoch 200, loss: 0.696524441242218\n",
      "In epoch 300, loss: 0.6948443651199341\n",
      "In epoch 400, loss: 0.6938888430595398\n",
      "In epoch 500, loss: 0.692686140537262\n",
      "AUC 0.7157485941945496\n",
      "ACC 0.9877246323075022\n",
      "Results for comp dataset\n",
      "AUC mean: 0.676254468080467\n",
      "AUC std: 0.023246981222087033\n",
      "ACC mean: 0.9880064268940798\n",
      "ACC std: 0.0013434911322364907\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 600x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "res = []\n",
    "datasets = ['comp']\n",
    "for ds in datasets:\n",
    "    data_total = pd.read_csv('data/w_removal_%s' % ds, sep=\" \", header=None)\n",
    "    print('Analyzing %s Dataset' % ds)\n",
    "    data_total.columns = [\"n1\", \"n2\", \"f1\", \"f2\", \"f3\", \"f4\", \"f5\", \"f6\", \"f7\", \"l\"]\n",
    "    data_total.dropna(subset=['n1', 'n2'], inplace=True)\n",
    "\n",
    "    # taking the unique values of the nodes and saving the indices\n",
    "    nodes = np.unique(data_total[['n1', 'n2']].values)\n",
    "    node_index = {node: idx for idx, node in enumerate(nodes)}\n",
    "\n",
    "    # creating an adj matrix (numpy) of size nodes*nodes filled with 0s\n",
    "    adj_matrix = np.zeros((len(nodes), len(nodes)), dtype=float)\n",
    "\n",
    "    # populating the adj matrix using the nodes and the labels\n",
    "    for _, row in data_total.iterrows():\n",
    "        i, j = node_index[row['n1']], node_index[row['n2']]\n",
    "        adj_matrix[i, j] = row['l']\n",
    "        adj_matrix[j, i] = row['l']\n",
    "\n",
    "    # turning the numpy matrix into a pandas df\n",
    "    adj_df = pd.DataFrame(adj_matrix, index=nodes, columns=nodes)\n",
    "\n",
    "    labels = data_total[\"l\"]\n",
    "    ones_label = np.where(labels == 1)\n",
    "\n",
    "    # Create graph using node indices\n",
    "    src = data_total[\"n1\"].map(node_index).astype(int)\n",
    "    dst = data_total[\"n2\"].map(node_index).astype(int)\n",
    "\n",
    "    src = torch.tensor(src.values[ones_label], dtype=torch.int64)\n",
    "    dst = torch.tensor(dst.values[ones_label], dtype=torch.int64)\n",
    "\n",
    "    \"\"\"g = dgl.graph((src, dst))\n",
    "\n",
    "    # Initialize node features as an identity matrix\n",
    "    inputs = torch.eye(g.number_of_nodes()).to(device)\"\"\"\n",
    "\n",
    "    comp_g = graph((torch.cat([src, dst]), torch.cat([dst, src])))\n",
    "    comp_g = comp_g\n",
    "    inputs_comp = comp_g.adj().to_dense()   \n",
    "    \n",
    "\n",
    "\n",
    "    \"\"\"\n",
    "    Generate all of the possible edges and remove 90% of them from the training set\n",
    "    \"\"\"\n",
    "    # K-fold cross validation\n",
    "    k = 10\n",
    "    auc_all = np.zeros((k,))\n",
    "    acc_all = np.zeros((k,))\n",
    "\n",
    "    for _ in range(k):\n",
    "        print('Fold %d of %d' % (_+1, k))\n",
    "\n",
    "    \n",
    "        upper_tri_idx = np.triu_indices_from(adj_df, k=1)\n",
    "        pairs = [(i, j) for i, j in zip(*upper_tri_idx)]\n",
    "        pairs += [(j, i) for i, j in pairs]  # Add (j, i) for each (i, j)\n",
    "        \n",
    "        np.random.shuffle(pairs)\n",
    "        possible_edges = np.array(pairs)\n",
    "        \n",
    "        test_size = int(len(possible_edges) * 0.25) # How much of the possible edges we will be removing\n",
    "        train_size = len(possible_edges) - test_size\n",
    "        \n",
    "        test_edges = possible_edges[:test_size]\n",
    "        train_edges = possible_edges[test_size:]\n",
    "    \n",
    "        test_pos_u = []\n",
    "        test_pos_v = []\n",
    "        test_neg_u = []\n",
    "        test_neg_v = []\n",
    "    \n",
    "        for u, v in test_edges:\n",
    "            if comp_g.has_edges_between(u, v):\n",
    "                test_pos_u.append(u)\n",
    "                test_pos_v.append(v)\n",
    "            else:\n",
    "                test_neg_u.append(u)\n",
    "                test_neg_v.append(v)\n",
    "    \n",
    "        train_pos_u = []\n",
    "        train_pos_v = []\n",
    "        train_neg_u = []\n",
    "        train_neg_v = []\n",
    "        \n",
    "        for u, v in train_edges:\n",
    "            if comp_g.has_edges_between(u, v):\n",
    "                train_pos_u.append(u)\n",
    "                train_pos_v.append(v)\n",
    "            else:\n",
    "                train_neg_u.append(u)\n",
    "                train_neg_v.append(v)\n",
    "                \n",
    "        #train_u, train_v = train_edges[:, 0], train_edges[:, 1]\n",
    "    \n",
    "        # Create subgraphs for training and testing\n",
    "        train_pos_g_comp = dgl.graph((torch.tensor(train_pos_u), torch.tensor(train_pos_v)), num_nodes=comp_g.number_of_nodes())\n",
    "        train_neg_g_comp = dgl.graph((torch.tensor(train_neg_u), torch.tensor(train_neg_v)), num_nodes=comp_g.number_of_nodes())\n",
    "    \n",
    "        test_pos_g_comp = dgl.graph((torch.tensor(test_pos_u), torch.tensor(test_pos_v)), num_nodes=comp_g.number_of_nodes())\n",
    "        test_neg_g_comp = dgl.graph((torch.tensor(test_neg_u), torch.tensor(test_neg_v)), num_nodes=comp_g.number_of_nodes())\n",
    "    \n",
    "        \n",
    "        model = GraphSAGE(comp_g.number_of_nodes(), 16)\n",
    "        pred = DotPredictor()\n",
    "        \n",
    "        optimizer = torch.optim.Adam(itertools.chain(model.parameters(), pred.parameters()), lr=0.001)\n",
    "        \n",
    "        for e in range(501):\n",
    "            h = model(train_pos_g_comp, inputs_comp)\n",
    "            pos_score = pred(train_pos_g_comp, h)\n",
    "            neg_score = pred(train_neg_g_comp, h)\n",
    "            loss = compute_loss(pos_score, neg_score)\n",
    "        \n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        \n",
    "            if e % 100 == 0:\n",
    "                print('In epoch {}, loss: {}'.format(e, loss.item()))\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            h = model(train_pos_g_comp, inputs_comp)\n",
    "            pos_score = pred(test_pos_g_comp, h)\n",
    "            neg_score = pred(test_neg_g_comp, h)\n",
    "            auc = compute_auc(pos_score, neg_score)\n",
    "            acc = compute_acc(pos_score, neg_score)\n",
    "            print('AUC', auc)\n",
    "            print('ACC', acc)\n",
    "    \n",
    "            auc_all[_] = compute_auc(pos_score, neg_score)\n",
    "            acc_all[_] = compute_acc(pos_score, neg_score)\n",
    "    \n",
    "            res.append({\n",
    "            'Dataset': ds,\n",
    "            'Test_Size': test_size,\n",
    "            'AUC': auc,\n",
    "            'ACC': acc\n",
    "        })\n",
    "\n",
    "torch.save({\n",
    "    'model_state_dict': model.state_dict(),\n",
    "    'optimizer_state_dict': optimizer.state_dict(),\n",
    "    'epoch': e\n",
    "}, 'model_comp_25p.pth')\n",
    "\n",
    "dgl.save_graphs(\"graphs_comp_25p.bin\", [train_pos_g_comp, train_neg_g_comp, test_pos_g_comp, test_neg_g_comp, comp_g])\n",
    "\n",
    "\n",
    "res.append({\n",
    "    'AUC mean': str(np.mean(auc_all)),\n",
    "    'AUC std': str(np.std(auc_all)),\n",
    "    'ACC mean': str(np.mean(acc_all)),\n",
    "    'ACC std': str(np.std(acc_all))\n",
    "})\n",
    "# Convert results to DataFrame\n",
    "results_df = pd.DataFrame(res)\n",
    "\n",
    "# Save to CSV\n",
    "results_df.to_csv('Comp_25p.csv', index=False)\n",
    "        \n",
    "# print results\n",
    "print('Results for %s dataset' % ds)\n",
    "print('AUC mean: ' + str(np.mean(auc_all)))\n",
    "print('AUC std: ' + str(np.std(auc_all)))\n",
    "\n",
    "print('ACC mean: ' + str(np.mean(acc_all)))\n",
    "print('ACC std: ' + str(np.std(acc_all)))\n",
    "\n",
    "# Generate true labels\n",
    "y_true_pos = [1] * len(pos_score)  # True labels for positive edges (1)\n",
    "y_true_neg = [0] * len(neg_score)  # True labels for negative edges (0)\n",
    "\n",
    "y_true = y_true_pos + y_true_neg  # Combine true labels for the test set\n",
    "\n",
    "# Generate predicted labels by thresholding the scores\n",
    "y_pred_pos = (pos_score >= 0.5).int().tolist()  # Predicted labels for positive edges\n",
    "y_pred_neg = (neg_score >= 0.5).int().tolist()  # Predicted labels for negative edges\n",
    "\n",
    "y_pred = y_pred_pos + y_pred_neg  # Combine predicted labels for the test set\n",
    "\n",
    "# Compute confusion matrix\n",
    "cm = confusion_matrix(y_true, y_pred)\n",
    "\n",
    "# Visualize the confusion matrix using seaborn with integer formatting\n",
    "plt.figure(figsize=(6, 6))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', cbar=False, \n",
    "            xticklabels=['Predicted 0', 'Predicted 1'],\n",
    "            yticklabels=['Actual 0', 'Actual 1'])\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.savefig('confusion_matrix_comp25p.png', dpi=200, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "np.save('cm_comp_25.npy', cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6659564473416898"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "G = nx.from_numpy_array(adj_matrix)\n",
    "nx.algebraic_connectivity(G)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of nodes and edges in train_pos_g_comp: 900 , 6466\n",
      "Number of nodes and edges in train_neg_g_comp: 900 , 762179\n",
      "Number of nodes and edges in test_pos_g_comp: 900 , 370\n",
      "Number of nodes and edges in test_neg_g_comp: 900 , 40085\n"
     ]
    }
   ],
   "source": [
    "print(f'Number of nodes and edges in train_pos_g_comp: {len(train_pos_g_comp.nodes())} , {len(train_pos_g_comp.edges()[0])}')\n",
    "print(f'Number of nodes and edges in train_neg_g_comp: {len(train_neg_g_comp.nodes())} , {len(train_neg_g_comp.edges()[0])}')\n",
    "print(f'Number of nodes and edges in test_pos_g_comp: {len(test_pos_g_comp.nodes())} , {len(test_pos_g_comp.edges()[0])}')\n",
    "print(f'Number of nodes and edges in test_neg_g_comp: {len(test_neg_g_comp.nodes())} , {len(test_neg_g_comp.edges()[0])}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ML Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analyzing ml Dataset\n",
      "Fold 1 of 10\n",
      "In epoch 0, loss: 4.464259624481201\n",
      "In epoch 100, loss: 0.7051791548728943\n",
      "In epoch 200, loss: 0.69587242603302\n",
      "In epoch 300, loss: 0.694146990776062\n",
      "In epoch 400, loss: 0.6935327053070068\n",
      "In epoch 500, loss: 0.6932535171508789\n",
      "AUC 0.6970764971300337\n",
      "ACC 0.9925003752030347\n",
      "Fold 2 of 10\n",
      "In epoch 0, loss: 2.936553955078125\n",
      "In epoch 100, loss: 0.6983568072319031\n",
      "In epoch 200, loss: 0.6941931843757629\n",
      "In epoch 300, loss: 0.6935017108917236\n",
      "In epoch 400, loss: 0.69306480884552\n",
      "In epoch 500, loss: 0.6924911141395569\n",
      "AUC 0.6285839573669585\n",
      "ACC 0.9927280846310184\n",
      "Fold 3 of 10\n",
      "In epoch 0, loss: 3.899531364440918\n",
      "In epoch 100, loss: 0.7179315686225891\n",
      "In epoch 200, loss: 0.6972572803497314\n",
      "In epoch 300, loss: 0.6933684945106506\n",
      "In epoch 400, loss: 0.6913366317749023\n",
      "In epoch 500, loss: 0.6893453001976013\n",
      "AUC 0.6834329888197267\n",
      "ACC 0.9919813751431501\n",
      "Fold 4 of 10\n",
      "In epoch 0, loss: 8.09299373626709\n",
      "In epoch 100, loss: 0.7241731286048889\n",
      "In epoch 200, loss: 0.6979043483734131\n",
      "In epoch 300, loss: 0.694260835647583\n",
      "In epoch 400, loss: 0.6932443380355835\n",
      "In epoch 500, loss: 0.6926146149635315\n",
      "AUC 0.6588665199354026\n",
      "ACC 0.9908202788553313\n",
      "Fold 5 of 10\n",
      "In epoch 0, loss: 3.9101336002349854\n",
      "In epoch 100, loss: 0.7113688588142395\n",
      "In epoch 200, loss: 0.6952088475227356\n",
      "In epoch 300, loss: 0.6936100125312805\n",
      "In epoch 400, loss: 0.6933002471923828\n",
      "In epoch 500, loss: 0.693126380443573\n",
      "AUC 0.6084634527955489\n",
      "ACC 0.9941083882090875\n",
      "Fold 6 of 10\n",
      "In epoch 0, loss: 1.6327757835388184\n",
      "In epoch 100, loss: 0.6964324116706848\n",
      "In epoch 200, loss: 0.6945040225982666\n",
      "In epoch 300, loss: 0.6927622556686401\n",
      "In epoch 400, loss: 0.690866231918335\n",
      "In epoch 500, loss: 0.688195526599884\n",
      "AUC 0.6977663765400955\n",
      "ACC 0.9916993259653069\n",
      "Fold 7 of 10\n",
      "In epoch 0, loss: 3.1973752975463867\n",
      "In epoch 100, loss: 0.6980373859405518\n",
      "In epoch 200, loss: 0.6934796571731567\n",
      "In epoch 300, loss: 0.6930629014968872\n",
      "In epoch 400, loss: 0.6927233338356018\n",
      "In epoch 500, loss: 0.6920418739318848\n",
      "AUC 0.6936470911675908\n",
      "ACC 0.9925702405957115\n",
      "Fold 8 of 10\n",
      "In epoch 0, loss: 2.4643476009368896\n",
      "In epoch 100, loss: 0.6998523473739624\n",
      "In epoch 200, loss: 0.6944764852523804\n",
      "In epoch 300, loss: 0.6935713291168213\n",
      "In epoch 400, loss: 0.6931628584861755\n",
      "In epoch 500, loss: 0.6927779316902161\n",
      "AUC 0.6869485653042848\n",
      "ACC 0.9928001679726689\n",
      "Fold 9 of 10\n",
      "In epoch 0, loss: 6.045309066772461\n",
      "In epoch 100, loss: 0.7189658284187317\n",
      "In epoch 200, loss: 0.6966238617897034\n",
      "In epoch 300, loss: 0.6936997771263123\n",
      "In epoch 400, loss: 0.6932430863380432\n",
      "In epoch 500, loss: 0.6928436160087585\n",
      "AUC 0.6506121371299589\n",
      "ACC 0.9930556017628258\n",
      "Fold 10 of 10\n",
      "In epoch 0, loss: 3.3194451332092285\n",
      "In epoch 100, loss: 0.7127079963684082\n",
      "In epoch 200, loss: 0.6953992247581482\n",
      "In epoch 300, loss: 0.6939147710800171\n",
      "In epoch 400, loss: 0.6932870149612427\n",
      "In epoch 500, loss: 0.6927680373191833\n",
      "AUC 0.6324648009663412\n",
      "ACC 0.9929461829467818\n",
      "Results for ml dataset\n",
      "AUC mean: 0.6637862387155942\n",
      "AUC std: 0.030912220958605324\n",
      "ACC mean: 0.9925210021284917\n",
      "ACC std: 0.0008347961036433817\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 600x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "res = []\n",
    "datasets = ['ml']\n",
    "for ds in datasets:\n",
    "    data_total = pd.read_csv('data/w_removal_%s' % ds, sep=\" \", header=None)\n",
    "    print('Analyzing %s Dataset' % ds)\n",
    "    data_total.columns = [\"n1\", \"n2\", \"f1\", \"f2\", \"f3\", \"f4\", \"f5\", \"f6\", \"f7\", \"l\"]\n",
    "    data_total.dropna(subset=['n1', 'n2'], inplace=True)\n",
    "\n",
    "    # taking the unique values of the nodes and saving the indices\n",
    "    nodes = np.unique(data_total[['n1', 'n2']].values)\n",
    "    node_index = {node: idx for idx, node in enumerate(nodes)}\n",
    "\n",
    "    # creating an adj matrix (numpy) of size nodes*nodes filled with 0s\n",
    "    adj_matrix = np.zeros((len(nodes), len(nodes)), dtype=float)\n",
    "\n",
    "    # populating the adj matrix using the nodes and the labels\n",
    "    for _, row in data_total.iterrows():\n",
    "        i, j = node_index[row['n1']], node_index[row['n2']]\n",
    "        adj_matrix[i, j] = row['l']\n",
    "        adj_matrix[j, i] = row['l']\n",
    "\n",
    "    # turning the numpy matrix into a pandas df\n",
    "    adj_df = pd.DataFrame(adj_matrix, index=nodes, columns=nodes)\n",
    "\n",
    "    labels = data_total[\"l\"]\n",
    "    ones_label = np.where(labels == 1)\n",
    "\n",
    "    # Create graph using node indices\n",
    "    src = data_total[\"n1\"].map(node_index).astype(int)\n",
    "    dst = data_total[\"n2\"].map(node_index).astype(int)\n",
    "\n",
    "    src = torch.tensor(src.values[ones_label], dtype=torch.int64)\n",
    "    dst = torch.tensor(dst.values[ones_label], dtype=torch.int64)\n",
    "\n",
    "    \"\"\"g = dgl.graph((src, dst))\n",
    "\n",
    "    # Initialize node features as an identity matrix\n",
    "    inputs = torch.eye(g.number_of_nodes()).to(device)\"\"\"\n",
    "\n",
    "    ml_g = graph((torch.cat([src, dst]), torch.cat([dst, src])))\n",
    "    ml_g = ml_g\n",
    "    inputs_ml = ml_g.adj().to_dense() \n",
    "    \n",
    "\n",
    "\n",
    "    \"\"\"\n",
    "    Generate all of the possible edges and remove 90% of them from the training set\n",
    "    \"\"\"\n",
    "    # K-fold cross validation\n",
    "    k = 10\n",
    "    auc_all = np.zeros((k,))\n",
    "    acc_all = np.zeros((k,))\n",
    "\n",
    "    for _ in range(k):\n",
    "        print('Fold %d of %d' % (_+1, k))\n",
    "\n",
    "    \n",
    "        upper_tri_idx = np.triu_indices_from(adj_df, k=1)\n",
    "        pairs = [(i, j) for i, j in zip(*upper_tri_idx)]\n",
    "        pairs += [(j, i) for i, j in pairs]  # Add (j, i) for each (i, j)\n",
    "        \n",
    "        np.random.shuffle(pairs)\n",
    "        possible_edges = np.array(pairs)\n",
    "        \n",
    "        test_size = int(len(possible_edges) * 0.25) # How much of the possible edges we will be removing\n",
    "        train_size = len(possible_edges) - test_size\n",
    "        \n",
    "        test_edges = possible_edges[:test_size]\n",
    "        train_edges = possible_edges[test_size:]\n",
    "    \n",
    "        \n",
    "        test_pos_u = []\n",
    "        test_pos_v = []\n",
    "        test_neg_u = []\n",
    "        test_neg_v = []\n",
    "    \n",
    "        for u, v in test_edges:\n",
    "            if ml_g.has_edges_between(u, v):\n",
    "                test_pos_u.append(u)\n",
    "                test_pos_v.append(v)\n",
    "            else:\n",
    "                test_neg_u.append(u)\n",
    "                test_neg_v.append(v)\n",
    "    \n",
    "        train_pos_u = []\n",
    "        train_pos_v = []\n",
    "        train_neg_u = []\n",
    "        train_neg_v = []\n",
    "        \n",
    "        for u, v in train_edges:\n",
    "            if ml_g.has_edges_between(u, v):\n",
    "                train_pos_u.append(u)\n",
    "                train_pos_v.append(v)\n",
    "            else:\n",
    "                train_neg_u.append(u)\n",
    "                train_neg_v.append(v)\n",
    "        \n",
    "    \n",
    "    \n",
    "            \n",
    "                \n",
    "        #train_u, train_v = train_edges[:, 0], train_edges[:, 1]\n",
    "    \n",
    "        # Create subgraphs for training and testing\n",
    "        train_pos_g_ml = dgl.graph((torch.tensor(train_pos_u), torch.tensor(train_pos_v)), num_nodes=ml_g.number_of_nodes())\n",
    "        train_neg_g_ml = dgl.graph((torch.tensor(train_neg_u), torch.tensor(train_neg_v)), num_nodes=ml_g.number_of_nodes())\n",
    "    \n",
    "        test_pos_g_ml = dgl.graph((torch.tensor(test_pos_u), torch.tensor(test_pos_v)), num_nodes=ml_g.number_of_nodes())\n",
    "        test_neg_g_ml = dgl.graph((torch.tensor(test_neg_u), torch.tensor(test_neg_v)), num_nodes=ml_g.number_of_nodes())\n",
    "    \n",
    "        \n",
    "        model = GraphSAGE(ml_g.number_of_nodes(), 16)\n",
    "        pred = DotPredictor()\n",
    "        \n",
    "        optimizer = torch.optim.Adam(itertools.chain(model.parameters(), pred.parameters()), lr=0.001)\n",
    "        \n",
    "        for e in range(501):\n",
    "            h = model(train_pos_g_ml, inputs_ml)\n",
    "            pos_score = pred(train_pos_g_ml, h)\n",
    "            neg_score = pred(train_neg_g_ml, h)\n",
    "            loss = compute_loss(pos_score, neg_score)\n",
    "        \n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        \n",
    "            if e % 100 == 0:\n",
    "                print('In epoch {}, loss: {}'.format(e, loss.item()))\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            h = model(train_pos_g_ml, inputs_ml)\n",
    "            pos_score = pred(test_pos_g_ml, h)\n",
    "            neg_score = pred(test_neg_g_ml, h)\n",
    "            auc = compute_auc(pos_score, neg_score)\n",
    "            acc = compute_acc(pos_score, neg_score)\n",
    "            print('AUC', auc)\n",
    "            print('ACC', acc)\n",
    "    \n",
    "            auc_all[_] = compute_auc(pos_score, neg_score)\n",
    "            acc_all[_] = compute_acc(pos_score, neg_score)\n",
    "    \n",
    "            res.append({\n",
    "            'Dataset': ds,\n",
    "            'Test_Size': test_size,\n",
    "            'AUC': auc,\n",
    "            'ACC': acc\n",
    "        })\n",
    "\n",
    "torch.save({\n",
    "    'model_state_dict': model.state_dict(),\n",
    "    'optimizer_state_dict': optimizer.state_dict(),\n",
    "    'epoch': e\n",
    "}, 'model_ml_25p.pth')\n",
    "\n",
    "dgl.save_graphs(\"graphs_ml_25p.bin\", [train_pos_g_ml, train_neg_g_ml, test_pos_g_ml, test_neg_g_ml, ml_g])\n",
    "\n",
    "res.append({\n",
    "    'AUC mean': str(np.mean(auc_all)),\n",
    "    'AUC std': str(np.std(auc_all)),\n",
    "    'ACC mean': str(np.mean(acc_all)),\n",
    "    'ACC std': str(np.std(acc_all))\n",
    "})\n",
    "# Convert results to DataFrame\n",
    "results_df = pd.DataFrame(res)\n",
    "\n",
    "# Save to CSV\n",
    "results_df.to_csv('ML_25p.csv', index=False)\n",
    "        \n",
    "# print results\n",
    "print('Results for %s dataset' % ds)\n",
    "print('AUC mean: ' + str(np.mean(auc_all)))\n",
    "print('AUC std: ' + str(np.std(auc_all)))\n",
    "\n",
    "print('ACC mean: ' + str(np.mean(acc_all)))\n",
    "print('ACC std: ' + str(np.std(acc_all)))\n",
    "\n",
    "# Generate true labels\n",
    "y_true_pos = [1] * len(pos_score)  # True labels for positive edges (1)\n",
    "y_true_neg = [0] * len(neg_score)  # True labels for negative edges (0)\n",
    "\n",
    "y_true = y_true_pos + y_true_neg  # Combine true labels for the test set\n",
    "\n",
    "# Generate predicted labels by thresholding the scores\n",
    "y_pred_pos = (pos_score >= 0.5).int().tolist()  # Predicted labels for positive edges\n",
    "y_pred_neg = (neg_score >= 0.5).int().tolist()  # Predicted labels for negative edges\n",
    "\n",
    "y_pred = y_pred_pos + y_pred_neg  # Combine predicted labels for the test set\n",
    "\n",
    "# Compute confusion matrix\n",
    "cm = confusion_matrix(y_true, y_pred)\n",
    "\n",
    "# Visualize the confusion matrix using seaborn with integer formatting\n",
    "plt.figure(figsize=(6, 6))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', cbar=False, \n",
    "            xticklabels=['Predicted 0', 'Predicted 1'],\n",
    "            yticklabels=['Actual 0', 'Actual 1'])\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.savefig('confusion_matrix_ml_25p.png', dpi=200, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "np.save('cm_ml_25.npy', cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9062134926786997"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "G = nx.from_numpy_array(adj_matrix)\n",
    "nx.algebraic_connectivity(G)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of nodes and edges in train_pos_g_ml: 3290 , 58130\n",
      "Number of nodes and edges in train_neg_g_ml: 3290 , 10221640\n",
      "Number of nodes and edges in test_pos_g_ml: 3290 , 3090\n",
      "Number of nodes and edges in test_neg_g_ml: 3290 , 537950\n"
     ]
    }
   ],
   "source": [
    "print(f'Number of nodes and edges in train_pos_g_ml: {len(train_pos_g_ml.nodes())} , {len(train_pos_g_ml.edges()[0])}')\n",
    "print(f'Number of nodes and edges in train_neg_g_ml: {len(train_neg_g_ml.nodes())} , {len(train_neg_g_ml.edges()[0])}')\n",
    "print(f'Number of nodes and edges in test_pos_g_ml: {len(test_pos_g_ml.nodes())} , {len(test_pos_g_ml.edges()[0])}')\n",
    "print(f'Number of nodes and edges in test_neg_g_ml: {len(test_neg_g_ml.nodes())} , {len(test_neg_g_ml.edges()[0])}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Shakespeare Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analyzing virtualshakespeare Dataset\n",
      "Fold 1 of 10\n",
      "In epoch 0, loss: 6.001633167266846\n",
      "In epoch 100, loss: 0.7041645050048828\n",
      "In epoch 200, loss: 0.6949606537818909\n",
      "In epoch 300, loss: 0.6930081248283386\n",
      "In epoch 400, loss: 0.691839337348938\n",
      "In epoch 500, loss: 0.6909031867980957\n",
      "AUC 0.679094285439368\n",
      "ACC 0.9755097759869945\n",
      "Fold 2 of 10\n",
      "In epoch 0, loss: 7.897585391998291\n",
      "In epoch 100, loss: 0.7057585716247559\n",
      "In epoch 200, loss: 0.6940833330154419\n",
      "In epoch 300, loss: 0.6919072270393372\n",
      "In epoch 400, loss: 0.6902981996536255\n",
      "In epoch 500, loss: 0.6890586614608765\n",
      "AUC 0.6514704397095159\n",
      "ACC 0.9742599180163093\n",
      "Fold 3 of 10\n",
      "In epoch 0, loss: 5.517745018005371\n",
      "In epoch 100, loss: 0.7071219682693481\n",
      "In epoch 200, loss: 0.6939898729324341\n",
      "In epoch 300, loss: 0.6918753385543823\n",
      "In epoch 400, loss: 0.6905013918876648\n",
      "In epoch 500, loss: 0.6892892718315125\n",
      "AUC 0.6642650591393482\n",
      "ACC 0.9772665693583771\n",
      "Fold 4 of 10\n",
      "In epoch 0, loss: 9.880390167236328\n",
      "In epoch 100, loss: 0.7352311611175537\n",
      "In epoch 200, loss: 0.69942706823349\n",
      "In epoch 300, loss: 0.6925994753837585\n",
      "In epoch 400, loss: 0.6905443668365479\n",
      "In epoch 500, loss: 0.6890944838523865\n",
      "AUC 0.5794369156323254\n",
      "ACC 0.9756059189078164\n",
      "Fold 5 of 10\n",
      "In epoch 0, loss: 20.427932739257812\n",
      "In epoch 100, loss: 0.7179333567619324\n",
      "In epoch 200, loss: 0.7017698884010315\n",
      "In epoch 300, loss: 0.6967683434486389\n",
      "In epoch 400, loss: 0.6947936415672302\n",
      "In epoch 500, loss: 0.6937780380249023\n",
      "AUC 0.6710568208669463\n",
      "ACC 0.9730100600456242\n",
      "Fold 6 of 10\n",
      "In epoch 0, loss: 9.865274429321289\n",
      "In epoch 100, loss: 0.7088892459869385\n",
      "In epoch 200, loss: 0.6959564685821533\n",
      "In epoch 300, loss: 0.6938988566398621\n",
      "In epoch 400, loss: 0.6928980350494385\n",
      "In epoch 500, loss: 0.6917791366577148\n",
      "AUC 0.6883172274084697\n",
      "ACC 0.9748018144791238\n",
      "Fold 7 of 10\n",
      "In epoch 0, loss: 9.711980819702148\n",
      "In epoch 100, loss: 0.7195475101470947\n",
      "In epoch 200, loss: 0.6995940208435059\n",
      "In epoch 300, loss: 0.69501131772995\n",
      "In epoch 400, loss: 0.6936455965042114\n",
      "In epoch 500, loss: 0.692384660243988\n",
      "AUC 0.6595761180850916\n",
      "ACC 0.9768470366129723\n",
      "Fold 8 of 10\n",
      "In epoch 0, loss: 9.781111717224121\n",
      "In epoch 100, loss: 0.7196504473686218\n",
      "In epoch 200, loss: 0.6963997483253479\n",
      "In epoch 300, loss: 0.6911907196044922\n",
      "In epoch 400, loss: 0.6894009113311768\n",
      "In epoch 500, loss: 0.6881118416786194\n",
      "AUC 0.7116189923110544\n",
      "ACC 0.9727303715486877\n",
      "Fold 9 of 10\n",
      "In epoch 0, loss: 10.978096961975098\n",
      "In epoch 100, loss: 0.7123432755470276\n",
      "In epoch 200, loss: 0.6935614943504333\n",
      "In epoch 300, loss: 0.688605010509491\n",
      "In epoch 400, loss: 0.6827861666679382\n",
      "In epoch 500, loss: 0.6708105802536011\n",
      "AUC 0.614863410116371\n",
      "ACC 0.9742074764231338\n",
      "Fold 10 of 10\n",
      "In epoch 0, loss: 5.858683109283447\n",
      "In epoch 100, loss: 0.6986783146858215\n",
      "In epoch 200, loss: 0.6946336030960083\n",
      "In epoch 300, loss: 0.6930534243583679\n",
      "In epoch 400, loss: 0.6912575364112854\n",
      "In epoch 500, loss: 0.6899328231811523\n",
      "AUC 0.6854738498877414\n",
      "ACC 0.9739627489883143\n",
      "Results for virtualshakespeare dataset\n",
      "AUC mean: 0.6605173118596233\n",
      "AUC std: 0.036357004531702694\n",
      "ACC mean: 0.9748201690367353\n",
      "ACC std: 0.001423184980447061\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 600x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "res = []\n",
    "datasets = ['virtualshakespeare']\n",
    "for ds in datasets:\n",
    "    data_total = pd.read_csv('data/w_removal_%s' % ds, sep=\" \", header=None)\n",
    "    print('Analyzing %s Dataset' % ds)\n",
    "    data_total.columns = [\"n1\", \"n2\", \"f1\", \"f2\", \"f3\", \"f4\", \"f5\", \"f6\", \"f7\", \"l\"]\n",
    "    data_total.dropna(subset=['n1', 'n2'], inplace=True)\n",
    "\n",
    "    # taking the unique values of the nodes and saving the indices\n",
    "    nodes = np.unique(data_total[['n1', 'n2']].values)\n",
    "    node_index = {node: idx for idx, node in enumerate(nodes)}\n",
    "\n",
    "    # creating an adj matrix (numpy) of size nodes*nodes filled with 0s\n",
    "    adj_matrix = np.zeros((len(nodes), len(nodes)), dtype=float)\n",
    "\n",
    "    # populating the adj matrix using the nodes and the labels\n",
    "    for _, row in data_total.iterrows():\n",
    "        i, j = node_index[row['n1']], node_index[row['n2']]\n",
    "        adj_matrix[i, j] = row['l']\n",
    "        adj_matrix[j, i] = row['l']\n",
    "\n",
    "    # turning the numpy matrix into a pandas df\n",
    "    adj_df = pd.DataFrame(adj_matrix, index=nodes, columns=nodes)\n",
    "\n",
    "    labels = data_total[\"l\"]\n",
    "    ones_label = np.where(labels == 1)\n",
    "\n",
    "    # Create graph using node indices\n",
    "    src = data_total[\"n1\"].map(node_index).astype(int)\n",
    "    dst = data_total[\"n2\"].map(node_index).astype(int)\n",
    "\n",
    "    src = torch.tensor(src.values[ones_label], dtype=torch.int64)\n",
    "    dst = torch.tensor(dst.values[ones_label], dtype=torch.int64)\n",
    "\n",
    "    \"\"\"g = dgl.graph((src, dst))\n",
    "\n",
    "    # Initialize node features as an identity matrix\n",
    "    inputs = torch.eye(g.number_of_nodes()).to(device)\"\"\"\n",
    "\n",
    "    shake_g = graph((torch.cat([src, dst]), torch.cat([dst, src])))\n",
    "    shake_g = shake_g\n",
    "    inputs_shake = shake_g.adj().to_dense()\n",
    "    \n",
    "\n",
    "\n",
    "    \"\"\"\n",
    "    Generate all of the possible edges and remove 90% of them from the training set\n",
    "    \"\"\"\n",
    "    # K-fold cross validation\n",
    "    k = 10\n",
    "    auc_all = np.zeros((k,))\n",
    "    acc_all = np.zeros((k,))\n",
    "\n",
    "    for _ in range(k):\n",
    "        print('Fold %d of %d' % (_+1, k))\n",
    "\n",
    "    \n",
    "        upper_tri_idx = np.triu_indices_from(adj_df, k=1)\n",
    "        pairs = [(i, j) for i, j in zip(*upper_tri_idx)]\n",
    "        pairs += [(j, i) for i, j in pairs]  # Add (j, i) for each (i, j)\n",
    "        \n",
    "        np.random.shuffle(pairs)\n",
    "        possible_edges = np.array(pairs)\n",
    "        \n",
    "        test_size = int(len(possible_edges) * 0.25) # How much of the possible edges we will be removing\n",
    "        train_size = len(possible_edges) - test_size\n",
    "        \n",
    "        test_edges = possible_edges[:test_size]\n",
    "        train_edges = possible_edges[test_size:]\n",
    "    \n",
    "        test_pos_u = []\n",
    "        test_pos_v = []\n",
    "        test_neg_u = []\n",
    "        test_neg_v = []\n",
    "    \n",
    "        for u, v in test_edges:\n",
    "            if shake_g.has_edges_between(u, v):\n",
    "                test_pos_u.append(u)\n",
    "                test_pos_v.append(v)\n",
    "            else:\n",
    "                test_neg_u.append(u)\n",
    "                test_neg_v.append(v)\n",
    "    \n",
    "        train_pos_u = []\n",
    "        train_pos_v = []\n",
    "        train_neg_u = []\n",
    "        train_neg_v = []\n",
    "        \n",
    "        for u, v in train_edges:\n",
    "            if shake_g.has_edges_between(u, v):\n",
    "                train_pos_u.append(u)\n",
    "                train_pos_v.append(v)\n",
    "            else:\n",
    "                train_neg_u.append(u)\n",
    "                train_neg_v.append(v)\n",
    "                \n",
    "        #train_u, train_v = train_edges[:, 0], train_edges[:, 1]\n",
    "    \n",
    "        # Create subgraphs for training and testing\n",
    "        train_pos_g_shake = dgl.graph((torch.tensor(train_pos_u), torch.tensor(train_pos_v)), num_nodes=shake_g.number_of_nodes())\n",
    "        train_neg_g_shake = dgl.graph((torch.tensor(train_neg_u), torch.tensor(train_neg_v)), num_nodes=shake_g.number_of_nodes())\n",
    "    \n",
    "        test_pos_g_shake = dgl.graph((torch.tensor(test_pos_u), torch.tensor(test_pos_v)), num_nodes=shake_g.number_of_nodes())\n",
    "        test_neg_g_shake = dgl.graph((torch.tensor(test_neg_u), torch.tensor(test_neg_v)), num_nodes=shake_g.number_of_nodes())\n",
    "    \n",
    "    \n",
    "        model = GraphSAGE(shake_g.number_of_nodes(), 16)\n",
    "        pred = DotPredictor()\n",
    "        \n",
    "        optimizer = torch.optim.Adam(itertools.chain(model.parameters(), pred.parameters()), lr=0.001)\n",
    "        \n",
    "        for e in range(501):\n",
    "            h = model(train_pos_g_shake, inputs_shake)\n",
    "            pos_score = pred(train_pos_g_shake, h)\n",
    "            neg_score = pred(train_neg_g_shake, h)\n",
    "            loss = compute_loss(pos_score, neg_score)\n",
    "        \n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        \n",
    "            if e % 100 == 0:\n",
    "                print('In epoch {}, loss: {}'.format(e, loss.item()))\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            h = model(train_pos_g_shake, inputs_shake)\n",
    "            pos_score = pred(test_pos_g_shake, h)\n",
    "            neg_score = pred(test_neg_g_shake, h)\n",
    "            auc = compute_auc(pos_score, neg_score)\n",
    "            acc = compute_acc(pos_score, neg_score)\n",
    "            print('AUC', auc)\n",
    "            print('ACC', acc)\n",
    "    \n",
    "            auc_all[_] = compute_auc(pos_score, neg_score)\n",
    "            acc_all[_] = compute_acc(pos_score, neg_score)\n",
    "    \n",
    "            res.append({\n",
    "            'Dataset': ds,\n",
    "            'Test_Size': test_size,\n",
    "            'AUC': auc,\n",
    "            'ACC': acc\n",
    "        })\n",
    "            \n",
    "torch.save({\n",
    "    'model_state_dict': model.state_dict(),\n",
    "    'optimizer_state_dict': optimizer.state_dict(),\n",
    "    'epoch': e\n",
    "}, 'model_shake_25p.pth')\n",
    "\n",
    "dgl.save_graphs(\"graphs_shake_25p.bin\", [train_pos_g_shake, train_neg_g_shake, test_pos_g_shake, test_neg_g_shake, shake_g])\n",
    "\n",
    "res.append({\n",
    "    'AUC mean': str(np.mean(auc_all)),\n",
    "    'AUC std': str(np.std(auc_all)),\n",
    "    'ACC mean': str(np.mean(acc_all)),\n",
    "    'ACC std': str(np.std(acc_all))\n",
    "})\n",
    "# Convert results to DataFrame\n",
    "results_df = pd.DataFrame(res)\n",
    "\n",
    "# Save to CSV\n",
    "results_df.to_csv('Shake_25p.csv', index=False)\n",
    "        \n",
    "# print results\n",
    "print('Results for %s dataset' % ds)\n",
    "print('AUC mean: ' + str(np.mean(auc_all)))\n",
    "print('AUC std: ' + str(np.std(auc_all)))\n",
    "\n",
    "print('ACC mean: ' + str(np.mean(acc_all)))\n",
    "print('ACC std: ' + str(np.std(acc_all)))\n",
    "\n",
    "# Generate true labels\n",
    "y_true_pos = [1] * len(pos_score)  # True labels for positive edges (1)\n",
    "y_true_neg = [0] * len(neg_score)  # True labels for negative edges (0)\n",
    "\n",
    "y_true = y_true_pos + y_true_neg  # Combine true labels for the test set\n",
    "\n",
    "# Generate predicted labels by thresholding the scores\n",
    "y_pred_pos = (pos_score >= 0.5).int().tolist()  # Predicted labels for positive edges\n",
    "y_pred_neg = (neg_score >= 0.5).int().tolist()  # Predicted labels for negative edges\n",
    "\n",
    "y_pred = y_pred_pos + y_pred_neg  # Combine predicted labels for the test set\n",
    "\n",
    "# Compute confusion matrix\n",
    "cm = confusion_matrix(y_true, y_pred)\n",
    "\n",
    "# Visualize the confusion matrix using seaborn with integer formatting\n",
    "plt.figure(figsize=(6, 6))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', cbar=False, \n",
    "            xticklabels=['Predicted 0', 'Predicted 1'],\n",
    "            yticklabels=['Actual 0', 'Actual 1'])\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.savefig('confusion_matrix_shake25p.png', dpi=200, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "np.save('cm_shake_25.npy', cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of nodes and edges in train_pos_g_shake: 677 , 8904\n",
      "Number of nodes and edges in train_neg_g_shake: 677 , 425866\n",
      "Number of nodes and edges in test_pos_g_shake: 677 , 500\n",
      "Number of nodes and edges in test_neg_g_shake: 677 , 22382\n"
     ]
    }
   ],
   "source": [
    "print(f'Number of nodes and edges in train_pos_g_shake: {len(train_pos_g_shake.nodes())} , {len(train_pos_g_shake.edges()[0])}')\n",
    "print(f'Number of nodes and edges in train_neg_g_shake: {len(train_neg_g_shake.nodes())} , {len(train_neg_g_shake.edges()[0])}')\n",
    "print(f'Number of nodes and edges in test_pos_g_shake: {len(test_pos_g_shake.nodes())} , {len(test_pos_g_shake.edges()[0])}')\n",
    "print(f'Number of nodes and edges in test_neg_g_shake: {len(test_neg_g_shake.nodes())} , {len(test_neg_g_shake.edges()[0])}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "\n",
    "def combineGraphs(g1, g2):\n",
    "    # Convert DGL graphs to NetworkX graphs\n",
    "    nx_g1 = g1.to_networkx()\n",
    "    nx_g2 = g2.to_networkx()\n",
    "    \n",
    "    # Relabel nodes in NetworkX graphs\n",
    "    # Offset for g2\n",
    "    offset = g1.num_nodes()\n",
    "    mapping_g2 = {i: i + offset for i in range(g2.num_nodes())}\n",
    "    nx_g2 = nx.relabel_nodes(nx_g2, mapping_g2)\n",
    "    \n",
    "    # Convert back to DGL graphs\n",
    "    g1_relabelled = dgl.from_networkx(nx_g1)\n",
    "    g2_relabelled = dgl.from_networkx(nx_g2)\n",
    "    \n",
    "    # Combine the relabeled DGL graphs\n",
    "    combined_g = dgl.batch([g1_relabelled, g2_relabelled])\n",
    "\n",
    "    return combined_g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_pos_g_combined = combineGraphs(train_pos_g_shake, train_pos_g_comp)\n",
    "train_neg_g_combined = combineGraphs(train_neg_g_shake, train_neg_g_comp)\n",
    "test_pos_g_combined = combineGraphs(test_pos_g_shake, test_pos_g_comp)\n",
    "test_neg_g_combined = combineGraphs(test_neg_g_shake, test_neg_g_comp)\n",
    "g = combineGraphs(shake_g, comp_g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_pos_g_combined = combineGraphs(train_pos_g_combined, train_pos_g_algo)\n",
    "train_neg_g_combined = combineGraphs(train_neg_g_combined, train_neg_g_algo)\n",
    "test_pos_g_combined = combineGraphs(test_pos_g_combined, test_pos_g_algo)\n",
    "test_neg_g_combined = combineGraphs(test_neg_g_combined, test_neg_g_algo)\n",
    "g = combineGraphs(g, algo_g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_pos_g_combined = combineGraphs(train_pos_g_combined, train_pos_g_ml)\n",
    "train_neg_g_combined = combineGraphs(train_neg_g_combined, train_neg_g_ml)\n",
    "test_pos_g_combined = combineGraphs(test_pos_g_combined, test_pos_g_ml)\n",
    "test_neg_g_combined = combineGraphs(test_neg_g_combined, test_neg_g_ml)\n",
    "g = combineGraphs(g, ml_g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = g.adj().to_dense()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of nodes and edges in train_pos_g_combined: 6032 , 81911\n",
      "Number of nodes and edges in train_neg_g_combined: 6032 , 12017349\n",
      "Number of nodes and edges in test_pos_g_combined: 6032 , 9095\n",
      "Number of nodes and edges in test_neg_g_combined: 6032 , 1335267\n",
      "Number of nodes and edges in g: 6032 , 91006\n"
     ]
    }
   ],
   "source": [
    "print(f'Number of nodes and edges in train_pos_g_combined: {len(train_pos_g_combined.nodes())} , {len(train_pos_g_combined.edges()[0])}')\n",
    "print(f'Number of nodes and edges in train_neg_g_combined: {len(train_neg_g_combined.nodes())} , {len(train_neg_g_combined.edges()[0])}')\n",
    "print(f'Number of nodes and edges in test_pos_g_combined: {len(test_pos_g_combined.nodes())} , {len(test_pos_g_combined.edges()[0])}')\n",
    "print(f'Number of nodes and edges in test_neg_g_combined: {len(test_neg_g_combined.nodes())} , {len(test_neg_g_combined.edges()[0])}')\n",
    "print(f'Number of nodes and edges in g: {len(g.nodes())} , {len(g.edges()[0])}') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1 of 10\n",
      "In epoch 0, loss: 1.2482246160507202\n",
      "In epoch 100, loss: 0.6947258710861206\n",
      "In epoch 200, loss: 0.6902198791503906\n",
      "In epoch 300, loss: 0.6877045035362244\n",
      "In epoch 400, loss: 0.6860408782958984\n",
      "In epoch 500, loss: 0.6844637989997864\n",
      "AUC for dataset 1: 0.7309675474475166\n",
      "ACC for dataset 1: 0.9737442423500826\n",
      "AUC for dataset 2: 0.724802331458518\n",
      "ACC for dataset 2: 0.9914423433444568\n",
      "AUC for dataset 3: 0.7777961261317953\n",
      "ACC for dataset 3: 0.9853192336622273\n",
      "AUC for dataset 4: 0.7051127806312433\n",
      "ACC for dataset 4: 0.9922271978210869\n",
      "Fold 2 of 10\n",
      "In epoch 0, loss: 2.2489352226257324\n",
      "In epoch 100, loss: 0.7073756456375122\n",
      "In epoch 200, loss: 0.6919397115707397\n",
      "In epoch 300, loss: 0.6903100609779358\n",
      "In epoch 400, loss: 0.6895163059234619\n",
      "In epoch 500, loss: 0.688839852809906\n",
      "AUC for dataset 1: 0.7094002645935208\n",
      "ACC for dataset 1: 0.9781755569734208\n",
      "AUC for dataset 2: 0.7158652844301943\n",
      "ACC for dataset 2: 0.9905623532319862\n",
      "AUC for dataset 3: 0.7771512570721564\n",
      "ACC for dataset 3: 0.986959279087946\n",
      "AUC for dataset 4: 0.7112413819085626\n",
      "ACC for dataset 4: 0.993852215102606\n",
      "Fold 3 of 10\n",
      "In epoch 0, loss: 1.6899470090866089\n",
      "In epoch 100, loss: 0.7013071775436401\n",
      "In epoch 200, loss: 0.6914580464363098\n",
      "In epoch 300, loss: 0.689383864402771\n",
      "In epoch 400, loss: 0.686739444732666\n",
      "In epoch 500, loss: 0.6836875677108765\n",
      "AUC for dataset 1: 0.6813393355618217\n",
      "ACC for dataset 1: 0.9778783879454258\n",
      "AUC for dataset 2: 0.6918863378979696\n",
      "ACC for dataset 2: 0.9886194537140032\n",
      "AUC for dataset 3: 0.7093256539378322\n",
      "ACC for dataset 3: 0.9835110540831526\n",
      "AUC for dataset 4: 0.6274118999759551\n",
      "ACC for dataset 4: 0.9923362469789687\n",
      "Fold 4 of 10\n",
      "In epoch 0, loss: 2.257993459701538\n",
      "In epoch 100, loss: 0.7042292952537537\n",
      "In epoch 200, loss: 0.6938846707344055\n",
      "In epoch 300, loss: 0.6918877363204956\n",
      "In epoch 400, loss: 0.6908366680145264\n",
      "In epoch 500, loss: 0.6894441246986389\n",
      "AUC for dataset 1: 0.6712220718655738\n",
      "ACC for dataset 1: 0.9777735047590745\n",
      "AUC for dataset 2: 0.5892216552473506\n",
      "ACC for dataset 2: 0.9902805586454084\n",
      "AUC for dataset 3: 0.6603046089283007\n",
      "ACC for dataset 3: 0.9873781396103417\n",
      "AUC for dataset 4: 0.6022743642843144\n",
      "ACC for dataset 4: 0.9928419393450101\n",
      "Fold 5 of 10\n",
      "In epoch 0, loss: 1.499601125717163\n",
      "In epoch 100, loss: 0.6935039758682251\n",
      "In epoch 200, loss: 0.6908121109008789\n",
      "In epoch 300, loss: 0.6888168454170227\n",
      "In epoch 400, loss: 0.6872818470001221\n",
      "In epoch 500, loss: 0.6857496500015259\n",
      "AUC for dataset 1: 0.6785417024957234\n",
      "ACC for dataset 1: 0.974740632620419\n",
      "AUC for dataset 2: 0.6370933759741999\n",
      "ACC for dataset 2: 0.990241008527994\n",
      "AUC for dataset 3: 0.7394887641100093\n",
      "ACC for dataset 3: 0.9851982950606906\n",
      "AUC for dataset 4: 0.6514472857028968\n",
      "ACC for dataset 4: 0.9922098238874583\n",
      "Fold 6 of 10\n",
      "In epoch 0, loss: 1.8749029636383057\n",
      "In epoch 100, loss: 0.6991795897483826\n",
      "In epoch 200, loss: 0.690635621547699\n",
      "In epoch 300, loss: 0.6885339617729187\n",
      "In epoch 400, loss: 0.6869176030158997\n",
      "In epoch 500, loss: 0.6840670704841614\n",
      "AUC for dataset 1: 0.6521707587861394\n",
      "ACC for dataset 1: 0.9764187636020383\n",
      "AUC for dataset 2: 0.6683649788391877\n",
      "ACC for dataset 2: 0.9877098010134717\n",
      "AUC for dataset 3: 0.7463859165631412\n",
      "ACC for dataset 3: 0.9823724613955135\n",
      "AUC for dataset 4: 0.6017724412955381\n",
      "ACC for dataset 4: 0.99074967414633\n",
      "Fold 7 of 10\n",
      "In epoch 0, loss: 2.6336989402770996\n",
      "In epoch 100, loss: 0.7089052200317383\n",
      "In epoch 200, loss: 0.691662073135376\n",
      "In epoch 300, loss: 0.689774215221405\n",
      "In epoch 400, loss: 0.6887399554252625\n",
      "In epoch 500, loss: 0.6878044605255127\n",
      "AUC for dataset 1: 0.7114269696730231\n",
      "ACC for dataset 1: 0.9766197897092114\n",
      "AUC for dataset 2: 0.6991459350139203\n",
      "ACC for dataset 2: 0.9878976640711902\n",
      "AUC for dataset 3: 0.7591141708270781\n",
      "ACC for dataset 3: 0.9843369762399894\n",
      "AUC for dataset 4: 0.6701129332538694\n",
      "ACC for dataset 4: 0.9918775011995408\n",
      "Fold 8 of 10\n",
      "In epoch 0, loss: 4.484649658203125\n",
      "In epoch 100, loss: 0.7082177996635437\n",
      "In epoch 200, loss: 0.694903552532196\n",
      "In epoch 300, loss: 0.6918110251426697\n",
      "In epoch 400, loss: 0.6903588771820068\n",
      "In epoch 500, loss: 0.6894845962524414\n",
      "AUC for dataset 1: 0.6955933836090001\n",
      "ACC for dataset 1: 0.9801945583106815\n",
      "AUC for dataset 2: 0.718992404396986\n",
      "ACC for dataset 2: 0.9900086515881844\n",
      "AUC for dataset 3: 0.764480201182467\n",
      "ACC for dataset 3: 0.9833989646475819\n",
      "AUC for dataset 4: 0.6487043698345213\n",
      "ACC for dataset 4: 0.9921628773008448\n",
      "Fold 9 of 10\n",
      "In epoch 0, loss: 1.7829501628875732\n",
      "In epoch 100, loss: 0.6984440684318542\n",
      "In epoch 200, loss: 0.6921517252922058\n",
      "In epoch 300, loss: 0.6901199221611023\n",
      "In epoch 400, loss: 0.6887980103492737\n",
      "In epoch 500, loss: 0.6869716644287109\n",
      "AUC for dataset 1: 0.7503099475802555\n",
      "ACC for dataset 1: 0.9758943476702823\n",
      "AUC for dataset 2: 0.7066926216884225\n",
      "ACC for dataset 2: 0.9874131751328636\n",
      "AUC for dataset 3: 0.7618774543630409\n",
      "ACC for dataset 3: 0.9856378036370073\n",
      "AUC for dataset 4: 0.6767053480953581\n",
      "ACC for dataset 4: 0.9920190802757058\n",
      "Fold 10 of 10\n",
      "In epoch 0, loss: 2.570493459701538\n",
      "In epoch 100, loss: 0.6997272372245789\n",
      "In epoch 200, loss: 0.6905442476272583\n",
      "In epoch 300, loss: 0.6892845630645752\n",
      "In epoch 400, loss: 0.6881815195083618\n",
      "In epoch 500, loss: 0.687108039855957\n",
      "AUC for dataset 1: 0.6373013110453287\n",
      "ACC for dataset 1: 0.9763226206812163\n",
      "AUC for dataset 2: 0.6849596800279838\n",
      "ACC for dataset 2: 0.9896032628846867\n",
      "AUC for dataset 3: 0.7420129236355957\n",
      "ACC for dataset 3: 0.9852513900564872\n",
      "AUC for dataset 4: 0.6098276746786396\n",
      "ACC for dataset 4: 0.9922771016729989\n",
      "AUC mean algo: 0.6918273292657904\n",
      "AUC std algo: 0.03303955692498433\n",
      "ACC mean algo: 0.9767762404621851\n",
      "ACC std algo: 0.0017413998089934894\n",
      "AUC mean comp: 0.6837024604974733\n",
      "AUC std comp: 0.04017324894526234\n",
      "ACC mean comp: 0.9893778272154246\n",
      "ACC std comp: 0.0013069918856427171\n",
      "AUC mean ml: 0.7437937076751416\n",
      "AUC std ml: 0.033831139025426754\n",
      "ACC mean ml: 0.9849363597480938\n",
      "ACC std ml: 0.0014895931324888664\n"
     ]
    }
   ],
   "source": [
    "k = 10\n",
    "\n",
    "auc_all_algo = np.zeros((k,))\n",
    "acc_all_algo = np.zeros((k,))\n",
    "\n",
    "auc_all_comp = np.zeros((k,))\n",
    "acc_all_comp = np.zeros((k,))\n",
    "\n",
    "auc_all_ml = np.zeros((k,))\n",
    "acc_all_ml = np.zeros((k,))\n",
    "\n",
    "auc_all_shake = np.zeros((k,))\n",
    "acc_all_shake = np.zeros((k,))\n",
    "\n",
    "res = []\n",
    "for _ in range(k):\n",
    "    print('Fold %d of %d' % (_+1, k))\n",
    "    \n",
    "    model = GraphSAGE(g.number_of_nodes(), 16)\n",
    "    pred = DotPredictor()\n",
    "    \n",
    "    optimizer = torch.optim.Adam(itertools.chain(model.parameters(), pred.parameters()), lr=0.001)\n",
    "    \n",
    "    for e in range(501):\n",
    "        h = model(train_pos_g_combined, inputs)\n",
    "        pos_score = pred(train_pos_g_combined, h)\n",
    "        neg_score = pred(train_neg_g_combined, h)\n",
    "        loss = compute_loss(pos_score, neg_score)\n",
    "    \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    \n",
    "        if e % 100 == 0:\n",
    "            print('In epoch {}, loss: {}'.format(e, loss.item()))\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        h = model(train_pos_g_combined, inputs)\n",
    "        pos_score = pred(test_pos_g_combined, h)\n",
    "        neg_score = pred(test_neg_g_combined, h)\n",
    "        #print('AUC', compute_auc(pos_score, neg_score))\n",
    "        #print('ACC', compute_acc(pos_score, neg_score))\n",
    "    \n",
    "    \n",
    "    nodes_dataset_1 = set(range(677))  # Node IDs from the first dataset\n",
    "    nodes_dataset_2 = set(range(677, 1577))  # Node IDs from the second dataset\n",
    "    nodes_dataset_3 = set(range(1577, 2742))\n",
    "    nodes_dataset_4 = set(range(2742, 6032))\n",
    "    \n",
    "    \n",
    "    pos_edges = list(zip(test_pos_g_combined.edges()[0].numpy(), test_pos_g_combined.edges()[1].numpy()))\n",
    "    neg_edges = list(zip(test_neg_g_combined.edges()[0].numpy(), test_neg_g_combined.edges()[1].numpy()))\n",
    "    \n",
    "    pos_score_1, pos_score_2, pos_score_3, pos_score_4 = [], [], [], []\n",
    "    neg_score_1, neg_score_2, neg_score_3, neg_score_4 = [], [], [], []\n",
    "    \n",
    "    \n",
    "    for i, edge in enumerate(pos_edges):\n",
    "        if edge[0] in nodes_dataset_1 and edge[1] in nodes_dataset_1:\n",
    "            pos_score_1.append(pos_score[i])\n",
    "        elif edge[0] in nodes_dataset_2 and edge[1] in nodes_dataset_2:\n",
    "            pos_score_2.append(pos_score[i])\n",
    "        elif edge[0] in nodes_dataset_3 and edge[1] in nodes_dataset_3:\n",
    "            pos_score_3.append(pos_score[i])\n",
    "        else:\n",
    "            pos_score_4.append(pos_score[i])\n",
    "    \n",
    "    for i, edge in enumerate(neg_edges):\n",
    "        if edge[0] in nodes_dataset_1 and edge[1] in nodes_dataset_1:\n",
    "            neg_score_1.append(neg_score[i])\n",
    "        elif edge[0] in nodes_dataset_2 and edge[1] in nodes_dataset_2:\n",
    "            neg_score_2.append(neg_score[i])\n",
    "        elif edge[0] in nodes_dataset_3 and edge[1] in nodes_dataset_3:\n",
    "            neg_score_3.append(neg_score[i])\n",
    "        else:\n",
    "            neg_score_4.append(neg_score[i])\n",
    "    \n",
    "    \n",
    "    pos_score_1 = torch.tensor(pos_score_1)\n",
    "    pos_score_2 = torch.tensor(pos_score_2)\n",
    "    neg_score_1 = torch.tensor(neg_score_1)\n",
    "    neg_score_2 = torch.tensor(neg_score_2)\n",
    "    pos_score_3 = torch.tensor(pos_score_3)\n",
    "    pos_score_4 = torch.tensor(pos_score_4)\n",
    "    neg_score_3 = torch.tensor(neg_score_3)\n",
    "    neg_score_4 = torch.tensor(neg_score_4)\n",
    "    \n",
    "    auc_1 = compute_auc(pos_score_1, neg_score_1)\n",
    "    acc_1 = compute_acc(pos_score_1, neg_score_1)\n",
    "    \n",
    "    auc_2 = compute_auc(pos_score_2, neg_score_2)\n",
    "    acc_2 = compute_acc(pos_score_2, neg_score_2)\n",
    "    \n",
    "    auc_3 = compute_auc(pos_score_3, neg_score_3)\n",
    "    acc_3 = compute_acc(pos_score_3, neg_score_3)\n",
    "    \n",
    "    auc_4 = compute_auc(pos_score_4, neg_score_4)\n",
    "    acc_4 = compute_acc(pos_score_4, neg_score_4)\n",
    "    \n",
    "    print('AUC for dataset 1:', auc_1)\n",
    "    print('ACC for dataset 1:', acc_1)\n",
    "    print('AUC for dataset 2:', auc_2)\n",
    "    print('ACC for dataset 2:', acc_2)\n",
    "    print('AUC for dataset 3:', auc_3)\n",
    "    print('ACC for dataset 3:', acc_3)\n",
    "    print('AUC for dataset 4:', auc_4)\n",
    "    print('ACC for dataset 4:', acc_4)\n",
    "\n",
    "    auc_all_algo[_] = auc_1\n",
    "    acc_all_algo[_] = acc_1\n",
    "\n",
    "    auc_all_comp[_] = auc_2\n",
    "    acc_all_comp[_] = acc_2\n",
    "\n",
    "    auc_all_ml[_] = auc_3\n",
    "    acc_all_ml[_] = acc_3\n",
    "\n",
    "    auc_all_shake[_] = auc_4\n",
    "    acc_all_shake[_] = acc_4\n",
    "\n",
    "    res.append({\n",
    "        'AUC Shake': auc_1,\n",
    "        'ACC Shake': acc_1,\n",
    "        'AUC Comp': auc_2,\n",
    "        'ACC Comp': acc_2,\n",
    "        'AUC Algo': auc_3,\n",
    "        'ACC Algo': acc_3,\n",
    "        'AUC ML': auc_4,\n",
    "        'ACC ML': acc_4,\n",
    "    })\n",
    "\n",
    "torch.save({\n",
    "    'model_state_dict': model.state_dict(),\n",
    "    'optimizer_state_dict': optimizer.state_dict(),\n",
    "    'epoch': e\n",
    "}, 'model_shake-comp-algo-ml_25p.pth')\n",
    "\n",
    "print('AUC mean algo: ' + str(np.mean(auc_all_algo)))\n",
    "print('AUC std algo: ' + str(np.std(auc_all_algo)))\n",
    "print('ACC mean algo: ' + str(np.mean(acc_all_algo)))\n",
    "print('ACC std algo: ' + str(np.std(acc_all_algo)))\n",
    "\n",
    "print('AUC mean comp: ' + str(np.mean(auc_all_comp)))\n",
    "print('AUC std comp: ' + str(np.std(auc_all_comp)))\n",
    "print('ACC mean comp: ' + str(np.mean(acc_all_comp)))\n",
    "print('ACC std comp: ' + str(np.std(acc_all_comp)))\n",
    "\n",
    "print('AUC mean ml: ' + str(np.mean(auc_all_ml)))\n",
    "print('AUC std ml: ' + str(np.std(auc_all_ml)))\n",
    "print('ACC mean ml: ' + str(np.mean(acc_all_ml)))\n",
    "print('ACC std ml: ' + str(np.std(acc_all_ml)))\n",
    "\n",
    "#print('AUC mean shake: ' + str(np.mean(auc_all_shake)))\n",
    "#print('AUC std shake: ' + str(np.std(auc_all_shake)))\n",
    "#print('ACC mean shake: ' + str(np.mean(acc_all_shake)))\n",
    "#print('ACC std shake: ' + str(np.std(acc_all_shake)))\n",
    "\n",
    "res.append({\n",
    "    'AUC mean shake': np.mean(auc_all_algo),\n",
    "    'AUC std shake' : np.std(auc_all_algo),\n",
    "    'ACC mean shake': np.mean(acc_all_algo),\n",
    "    'ACC std shake' : np.std(acc_all_algo),\n",
    "    'AUC mean comp': np.mean(auc_all_comp),\n",
    "    'AUC std comp' : np.std(auc_all_comp),\n",
    "    'ACC mean comp': np.mean(acc_all_comp),\n",
    "    'ACC std comp' : np.std(acc_all_comp),\n",
    "    'AUC mean algo': np.mean(auc_all_ml),\n",
    "    'AUC std algo' : np.std(auc_all_ml),\n",
    "    'ACC mean algo': np.mean(acc_all_ml),\n",
    "    'ACC std algo' : np.std(acc_all_ml),\n",
    "    'AUC mean ml': np.mean(auc_all_shake),\n",
    "    'AUC std ml' : np.std(auc_all_shake),\n",
    "    'ACC mean ml': np.mean(acc_all_shake),\n",
    "    'ACC std ml' : np.std(acc_all_shake),\n",
    "\n",
    "})\n",
    "\n",
    "# Convert results to DataFrame\n",
    "results_df = pd.DataFrame(res)\n",
    "\n",
    "# Save to CSV\n",
    "results_df.to_csv('Combined_25p.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "T-statistic: -0.124\n",
      "P-value for 20p: 0.451\n",
      "For 0.1 alpha, Fail to reject the null hypothesis (H0). No significant difference between the models.\n",
      "For 0.01 alpha, Fail to reject the null hypothesis (H0). No significant difference between the models.\n",
      "For 0.05 alpha, Fail to reject the null hypothesis (H0). No significant difference between the models.\n"
     ]
    }
   ],
   "source": [
    "import scipy.stats as stats\n",
    "import pandas as pd\n",
    "datasets = ['20p']\n",
    "for ds in datasets:\n",
    "    data = pd.read_csv('New_20_Percent/Shake_%s.csv' % ds)\n",
    "    data_combined = pd.read_csv('New_20_Percent/Combined_%s.csv' % ds)\n",
    "    \n",
    "    auc_val  = data['AUC'].dropna().values\n",
    "    auc_combined = data_combined['AUC Shake'].dropna().values\n",
    "    t_stat, p_value = stats.ttest_ind(auc_val, auc_combined, alternative='less', equal_var=False)\n",
    "    \n",
    "    # Display the results\n",
    "    print(f'T-statistic: {t_stat:.3f}')\n",
    "    print(f'P-value for %s: {p_value:.3f}' % ds)\n",
    "    \n",
    "    alphas = [0.1, 0.01, 0.05]\n",
    "    for alpha in alphas:    \n",
    "        if p_value < alpha:\n",
    "            print(\"For %s alpha, Reject the null hypothesis (H0). The combined model performs better.\" % alpha)\n",
    "        else:\n",
    "            print(\"For %s alpha, Fail to reject the null hypothesis (H0). No significant difference between the models.\" % alpha)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "graphs, _ = dgl.load_graphs(\"graphs_algo_25p.bin\")\n",
    "\n",
    "# Unpack each graph\n",
    "train_pos_g_algo = graphs[0]\n",
    "train_neg_g_algo = graphs[1]\n",
    "test_pos_g_algo = graphs[2]\n",
    "test_neg_g_algo = graphs[3]\n",
    "algo_g = graphs[4]\n",
    "\n",
    "graphs, _ = dgl.load_graphs(\"graphs_comp_25p.bin\")\n",
    "\n",
    "\n",
    "train_pos_g_comp = graphs[0]\n",
    "train_neg_g_comp = graphs[1]\n",
    "test_pos_g_comp = graphs[2]\n",
    "test_neg_g_comp = graphs[3]\n",
    "comp_g = graphs[4]\n",
    "\n",
    "graphs, _ = dgl.load_graphs(\"graphs_ml_25p.bin\")\n",
    "\n",
    "train_pos_g_ml = graphs[0]\n",
    "train_neg_g_ml = graphs[1]\n",
    "test_pos_g_ml = graphs[2]\n",
    "test_neg_g_ml = graphs[3]\n",
    "ml_g = graphs[4]\n",
    "\n",
    "graphs, _ = dgl.load_graphs(\"graphs_shake_25p.bin\")\n",
    "\n",
    "train_pos_g_shake = graphs[0]\n",
    "train_neg_g_shake = graphs[1]\n",
    "test_pos_g_shake = graphs[2]\n",
    "test_neg_g_shake = graphs[3]\n",
    "shake_g = graphs[4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_pos_g_combined = combineGraphs(train_pos_g_algo, train_pos_g_shake)\n",
    "train_neg_g_combined = combineGraphs(train_neg_g_algo, train_neg_g_shake)\n",
    "test_pos_g_combined = combineGraphs(test_pos_g_algo, test_pos_g_shake)\n",
    "test_neg_g_combined = combineGraphs(test_neg_g_algo, test_neg_g_shake)\n",
    "g = combineGraphs(algo_g, shake_g)\n",
    "\n",
    "train_pos_g_combined = combineGraphs(train_pos_g_combined, train_pos_g_comp)\n",
    "train_neg_g_combined = combineGraphs(train_neg_g_combined, train_neg_g_comp)\n",
    "test_pos_g_combined = combineGraphs(test_pos_g_combined, test_pos_g_comp)\n",
    "test_neg_g_combined = combineGraphs(test_neg_g_combined, test_neg_g_comp)\n",
    "g = combineGraphs(g, comp_g)\n",
    "\n",
    "train_pos_g_combined = combineGraphs(train_pos_g_combined, train_pos_g_ml)\n",
    "train_neg_g_combined = combineGraphs(train_neg_g_combined, train_neg_g_ml)\n",
    "test_pos_g_combined = combineGraphs(test_pos_g_combined, test_pos_g_ml)\n",
    "test_neg_g_combined = combineGraphs(test_neg_g_combined, test_neg_g_ml)\n",
    "g = combineGraphs(g, ml_g)\n",
    "\n",
    "inputs = g.adj().to_dense()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1 of 10\n",
      "In epoch 0, loss: 1.310952067375183\n",
      "In epoch 100, loss: 0.6954591870307922\n",
      "In epoch 200, loss: 0.6918495297431946\n",
      "In epoch 300, loss: 0.6892198920249939\n",
      "In epoch 400, loss: 0.6863341927528381\n",
      "In epoch 500, loss: 0.684011697769165\n",
      "AUC for dataset 1: 0.7716563053869703\n",
      "ACC for dataset 1: 0.9840420040411191\n",
      "AUC for dataset 2: 0.7179924206243075\n",
      "ACC for dataset 2: 0.9787605978498383\n",
      "AUC for dataset 3: 0.7595668511179241\n",
      "ACC for dataset 3: 0.9895933753553331\n",
      "Fold 2 of 10\n",
      "In epoch 0, loss: 2.945615291595459\n",
      "In epoch 100, loss: 0.6993197202682495\n",
      "In epoch 200, loss: 0.6917494535446167\n",
      "In epoch 300, loss: 0.6896839141845703\n",
      "In epoch 400, loss: 0.6872678995132446\n",
      "In epoch 500, loss: 0.683975338935852\n",
      "AUC for dataset 1: 0.7498771416295182\n",
      "ACC for dataset 1: 0.9844549651195375\n",
      "AUC for dataset 2: 0.7104218007743348\n",
      "ACC for dataset 2: 0.9786294904291583\n",
      "AUC for dataset 3: 0.7285585057074251\n",
      "ACC for dataset 3: 0.989395624768261\n",
      "Fold 3 of 10\n",
      "In epoch 0, loss: 1.8304091691970825\n",
      "In epoch 100, loss: 0.7031381130218506\n",
      "In epoch 200, loss: 0.6913270354270935\n",
      "In epoch 300, loss: 0.6871835589408875\n",
      "In epoch 400, loss: 0.6825093626976013\n",
      "In epoch 500, loss: 0.6769301295280457\n",
      "AUC for dataset 1: 0.7548108375246236\n",
      "ACC for dataset 1: 0.9846171998289162\n",
      "AUC for dataset 2: 0.7196865766566054\n",
      "ACC for dataset 2: 0.9797220522681583\n",
      "AUC for dataset 3: 0.6892502246293468\n",
      "ACC for dataset 3: 0.9881349647756766\n",
      "Fold 4 of 10\n",
      "In epoch 0, loss: 1.439387559890747\n",
      "In epoch 100, loss: 0.7007866501808167\n",
      "In epoch 200, loss: 0.6936023235321045\n",
      "In epoch 300, loss: 0.6920818090438843\n",
      "In epoch 400, loss: 0.6908372640609741\n",
      "In epoch 500, loss: 0.6892330646514893\n",
      "AUC for dataset 1: 0.7691146011098617\n",
      "ACC for dataset 1: 0.9860478149934369\n",
      "AUC for dataset 2: 0.6798256035163464\n",
      "ACC for dataset 2: 0.9785420854820382\n",
      "AUC for dataset 3: 0.6945909579714634\n",
      "ACC for dataset 3: 0.9909281918180695\n",
      "Fold 5 of 10\n",
      "In epoch 0, loss: 1.4150495529174805\n",
      "In epoch 100, loss: 0.6934639811515808\n",
      "In epoch 200, loss: 0.6899483799934387\n",
      "In epoch 300, loss: 0.6881920099258423\n",
      "In epoch 400, loss: 0.6866788268089294\n",
      "In epoch 500, loss: 0.6857622861862183\n",
      "AUC for dataset 1: 0.8124815809899356\n",
      "ACC for dataset 1: 0.9863427871923072\n",
      "AUC for dataset 2: 0.6821234151925011\n",
      "ACC for dataset 2: 0.9768813914867581\n",
      "AUC for dataset 3: 0.7073911957165527\n",
      "ACC for dataset 3: 0.9881596835990607\n",
      "Fold 6 of 10\n",
      "In epoch 0, loss: 2.1905298233032227\n",
      "In epoch 100, loss: 0.7040832042694092\n",
      "In epoch 200, loss: 0.6912696361541748\n",
      "In epoch 300, loss: 0.6884230971336365\n",
      "In epoch 400, loss: 0.686461329460144\n",
      "In epoch 500, loss: 0.6846475005149841\n",
      "AUC for dataset 1: 0.780344977988146\n",
      "ACC for dataset 1: 0.9852513900564872\n",
      "AUC for dataset 2: 0.6622930238222596\n",
      "ACC for dataset 2: 0.9798531596888383\n",
      "AUC for dataset 3: 0.6878006309206302\n",
      "ACC for dataset 3: 0.9890248424175009\n",
      "Fold 7 of 10\n",
      "In epoch 0, loss: 1.83365797996521\n",
      "In epoch 100, loss: 0.7143045663833618\n",
      "In epoch 200, loss: 0.695178747177124\n",
      "In epoch 300, loss: 0.6926131248474121\n",
      "In epoch 400, loss: 0.6909281015396118\n",
      "In epoch 500, loss: 0.6892693638801575\n",
      "AUC for dataset 1: 0.6974328816037727\n",
      "ACC for dataset 1: 0.9856053566951315\n",
      "AUC for dataset 2: 0.710807256842293\n",
      "ACC for dataset 2: 0.9784983830084782\n",
      "AUC for dataset 3: 0.6581905438463428\n",
      "ACC for dataset 3: 0.9881349647756766\n",
      "Fold 8 of 10\n",
      "In epoch 0, loss: 3.1172988414764404\n",
      "In epoch 100, loss: 0.7291017174720764\n",
      "In epoch 200, loss: 0.6976419687271118\n",
      "In epoch 300, loss: 0.6924170255661011\n",
      "In epoch 400, loss: 0.6914622187614441\n",
      "In epoch 500, loss: 0.6909593939781189\n",
      "AUC for dataset 1: 0.684954440833072\n",
      "ACC for dataset 1: 0.9864902732917422\n",
      "AUC for dataset 2: 0.6512582245220901\n",
      "ACC for dataset 2: 0.9803338868979984\n",
      "AUC for dataset 3: 0.6360204507661137\n",
      "ACC for dataset 3: 0.989296749474725\n",
      "Fold 9 of 10\n",
      "In epoch 0, loss: 1.2945343255996704\n",
      "In epoch 100, loss: 0.6939822435379028\n",
      "In epoch 200, loss: 0.6919996738433838\n",
      "In epoch 300, loss: 0.6908354759216309\n",
      "In epoch 400, loss: 0.6893330216407776\n",
      "In epoch 500, loss: 0.68696129322052\n",
      "AUC for dataset 1: 0.7675059317658515\n",
      "ACC for dataset 1: 0.9855758594752445\n",
      "AUC for dataset 2: 0.6339972251939021\n",
      "ACC for dataset 2: 0.9786731929027183\n",
      "AUC for dataset 3: 0.6688692657201967\n",
      "ACC for dataset 3: 0.989568656531949\n",
      "Fold 10 of 10\n",
      "In epoch 0, loss: 1.8706127405166626\n",
      "In epoch 100, loss: 0.6971396207809448\n",
      "In epoch 200, loss: 0.6921212077140808\n",
      "In epoch 300, loss: 0.6904603242874146\n",
      "In epoch 400, loss: 0.689054548740387\n",
      "In epoch 500, loss: 0.687371015548706\n",
      "AUC for dataset 1: 0.7773889813388681\n",
      "ACC for dataset 1: 0.9843517248499329\n",
      "AUC for dataset 2: 0.6401827304537755\n",
      "ACC for dataset 2: 0.9791102176383183\n",
      "AUC for dataset 3: 0.7101125639318266\n",
      "ACC for dataset 3: 0.9888518106538129\n",
      "AUC mean Comp: 0.756556768017062\n",
      "AUC std Comp: 0.03647357539900698\n",
      "ACC mean Comp: 0.9852779375543855\n",
      "ACC std Comp: 0.0008301987165972248\n",
      "AUC mean Algo: 0.6808588277598414\n",
      "AUC std algo: 0.0311953230309876\n",
      "ACC mean algo: 0.9789004457652302\n",
      "ACC std algo: 0.0009051372059085444\n",
      "AUC mean Algo: 0.6940351190327823\n",
      "AUC std Algo: 0.03356943497762081\n",
      "ACC mean Algo: 0.9891088864170066\n",
      "ACC std Algo: 0.0008212603546500647\n"
     ]
    }
   ],
   "source": [
    "k = 10\n",
    "\n",
    "auc_all_algo = np.zeros((k,))\n",
    "acc_all_algo = np.zeros((k,))\n",
    "\n",
    "auc_all_comp = np.zeros((k,))\n",
    "acc_all_comp = np.zeros((k,))\n",
    "\n",
    "auc_all_ml = np.zeros((k,))\n",
    "acc_all_ml = np.zeros((k,))\n",
    "\n",
    "auc_all_shake = np.zeros((k,))\n",
    "acc_all_shake = np.zeros((k,))\n",
    "\n",
    "res = []\n",
    "for _ in range(k):\n",
    "    print('Fold %d of %d' % (_+1, k))\n",
    "    \n",
    "    model = GraphSAGE(g.number_of_nodes(), 16)\n",
    "    pred = DotPredictor()\n",
    "    \n",
    "    optimizer = torch.optim.Adam(itertools.chain(model.parameters(), pred.parameters()), lr=0.001)\n",
    "    \n",
    "    for e in range(501):\n",
    "        h = model(train_pos_g_combined, inputs)\n",
    "        pos_score = pred(train_pos_g_combined, h)\n",
    "        neg_score = pred(train_neg_g_combined, h)\n",
    "        loss = compute_loss(pos_score, neg_score)\n",
    "    \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    \n",
    "        if e % 100 == 0:\n",
    "            print('In epoch {}, loss: {}'.format(e, loss.item()))\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        h = model(train_pos_g_combined, inputs)\n",
    "        pos_score = pred(test_pos_g_combined, h)\n",
    "        neg_score = pred(test_neg_g_combined, h)\n",
    "        #print('AUC', compute_auc(pos_score, neg_score))\n",
    "        #print('ACC', compute_acc(pos_score, neg_score))\n",
    "    \n",
    "    \n",
    "    nodes_dataset_1 = set(range(1165))  # Node IDs from the first dataset\n",
    "    nodes_dataset_2 = set(range(1165, 1842))  # Node IDs from the second dataset\n",
    "    nodes_dataset_3 = set(range(1842, 2742))\n",
    "    nodes_dataset_4 = set(range(2742, 6032))\n",
    "    \n",
    "    \n",
    "    pos_edges = list(zip(test_pos_g_combined.edges()[0].numpy(), test_pos_g_combined.edges()[1].numpy()))\n",
    "    neg_edges = list(zip(test_neg_g_combined.edges()[0].numpy(), test_neg_g_combined.edges()[1].numpy()))\n",
    "    \n",
    "    pos_score_1, pos_score_2, pos_score_3, pos_score_4 = [], [], [], []\n",
    "    neg_score_1, neg_score_2, neg_score_3, neg_score_4 = [], [], [], []\n",
    "    \n",
    "    \n",
    "    for i, edge in enumerate(pos_edges):\n",
    "        if edge[0] in nodes_dataset_1 and edge[1] in nodes_dataset_1:\n",
    "            pos_score_1.append(pos_score[i])\n",
    "        elif edge[0] in nodes_dataset_2 and edge[1] in nodes_dataset_2:\n",
    "            pos_score_2.append(pos_score[i])\n",
    "        elif edge[0] in nodes_dataset_3 and edge[1] in nodes_dataset_3:\n",
    "            pos_score_3.append(pos_score[i])\n",
    "        else:\n",
    "            pos_score_4.append(pos_score[i])\n",
    "        \n",
    "    \n",
    "    for i, edge in enumerate(neg_edges):\n",
    "        if edge[0] in nodes_dataset_1 and edge[1] in nodes_dataset_1:\n",
    "            neg_score_1.append(neg_score[i])\n",
    "        elif edge[0] in nodes_dataset_2 and edge[1] in nodes_dataset_2:\n",
    "            neg_score_2.append(neg_score[i])\n",
    "        elif edge[0] in nodes_dataset_3 and edge[1] in nodes_dataset_3:\n",
    "            neg_score_3.append(neg_score[i])\n",
    "        else:\n",
    "            neg_score_4.append(neg_score[i])\n",
    "    \n",
    "    \n",
    "    pos_score_1 = torch.tensor(pos_score_1)\n",
    "    pos_score_2 = torch.tensor(pos_score_2)\n",
    "    pos_score_3 = torch.tensor(pos_score_3)\n",
    "    pos_score_4 = torch.tensor(pos_score_4)\n",
    "    \n",
    "    neg_score_1 = torch.tensor(neg_score_1)\n",
    "    neg_score_2 = torch.tensor(neg_score_2)\n",
    "    neg_score_3 = torch.tensor(neg_score_3)\n",
    "    neg_score_4 = torch.tensor(neg_score_4)\n",
    "    \n",
    "    \n",
    "    auc_1 = compute_auc(pos_score_1, neg_score_1)\n",
    "    acc_1 = compute_acc(pos_score_1, neg_score_1)\n",
    "    \n",
    "    auc_2 = compute_auc(pos_score_2, neg_score_2)\n",
    "    acc_2 = compute_acc(pos_score_2, neg_score_2)\n",
    "    \n",
    "    auc_3 = compute_auc(pos_score_3, neg_score_3)\n",
    "    acc_3 = compute_acc(pos_score_3, neg_score_3)\n",
    "\n",
    "    auc_4 = compute_auc(pos_score_4, neg_score_4)\n",
    "    acc_4 = compute_acc(pos_score_4, neg_score_4)\n",
    "    \n",
    "    \n",
    "    print('AUC for dataset 1:', auc_1)\n",
    "    print('ACC for dataset 1:', acc_1)\n",
    "    print('AUC for dataset 2:', auc_2)\n",
    "    print('ACC for dataset 2:', acc_2)    \n",
    "    print('AUC for dataset 3:', auc_3)\n",
    "    print('ACC for dataset 3:', acc_3)\n",
    "    \n",
    "\n",
    "    auc_all_algo[_] = auc_1\n",
    "    acc_all_algo[_] = acc_1\n",
    "\n",
    "    auc_all_comp[_] = auc_2\n",
    "    acc_all_comp[_] = acc_2\n",
    "\n",
    "    auc_all_ml[_] = auc_3\n",
    "    acc_all_ml[_] = acc_3\n",
    "\n",
    "    auc_all_shake[_] = auc_4\n",
    "    acc_all_shake[_] = acc_4\n",
    "    \n",
    "\n",
    "    res.append({\n",
    "        'AUC Algo': auc_1,\n",
    "        'ACC Algo': acc_1,\n",
    "        'AUC Shake': auc_2,\n",
    "        'ACC Shake': acc_2,\n",
    "        'AUC Comp': auc_3,\n",
    "        'ACC Comp': acc_3,\n",
    "        'AUC ML': auc_4,\n",
    "        'ACC ML': acc_4,\n",
    "    })\n",
    "\n",
    "print('AUC mean Comp: ' + str(np.mean(auc_all_algo)))\n",
    "print('AUC std Comp: ' + str(np.std(auc_all_algo)))\n",
    "print('ACC mean Comp: ' + str(np.mean(acc_all_algo)))\n",
    "print('ACC std Comp: ' + str(np.std(acc_all_algo)))\n",
    "\n",
    "print('AUC mean Algo: ' + str(np.mean(auc_all_comp)))\n",
    "print('AUC std algo: ' + str(np.std(auc_all_comp)))\n",
    "print('ACC mean algo: ' + str(np.mean(acc_all_comp)))\n",
    "print('ACC std algo: ' + str(np.std(acc_all_comp)))\n",
    "\n",
    "print('AUC mean Algo: ' + str(np.mean(auc_all_ml)))\n",
    "print('AUC std Algo: ' + str(np.std(auc_all_ml)))\n",
    "print('ACC mean Algo: ' + str(np.mean(acc_all_ml)))\n",
    "print('ACC std Algo: ' + str(np.std(acc_all_ml)))\n",
    "\n",
    "\n",
    "\n",
    "res.append({\n",
    "    'AUC mean algo': np.mean(auc_all_algo),\n",
    "    'AUC std algo' : np.std(auc_all_algo),\n",
    "    'ACC mean algo': np.mean(acc_all_algo),\n",
    "    'ACC std algo' : np.std(acc_all_algo),\n",
    "    'AUC mean shake': np.mean(auc_all_comp),\n",
    "    'AUC std shake' : np.std(auc_all_comp),\n",
    "    'ACC mean shake': np.mean(acc_all_comp),\n",
    "    'ACC std shake' : np.std(acc_all_comp),\n",
    "    'AUC mean comp': np.mean(auc_all_ml),\n",
    "    'AUC std comp' : np.std(auc_all_ml),\n",
    "    'ACC mean comp': np.mean(acc_all_ml),\n",
    "    'ACC std comp' : np.std(acc_all_ml),\n",
    "    'AUC mean ml': np.mean(auc_all_shake),\n",
    "    'AUC std ml' : np.std(auc_all_shake),\n",
    "    'ACC mean ml': np.mean(acc_all_shake),\n",
    "    'ACC std ml' : np.std(acc_all_shake),\n",
    "\n",
    "})\n",
    "\n",
    "# Convert results to DataFrame\n",
    "results_df = pd.DataFrame(res)\n",
    "\n",
    "# Save to CSV\n",
    "results_df.to_csv('Combined_5p.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 600x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Generate true labels\n",
    "y_true_pos = [1] * len(pos_score_4)  # True labels for positive edges (1)\n",
    "y_true_neg = [0] * len(neg_score_4)  # True labels for negative edges (0)\n",
    "\n",
    "y_true = y_true_pos + y_true_neg  # Combine true labels for the test set\n",
    "\n",
    "# Generate predicted labels by thresholding the scores\n",
    "y_pred_pos = (pos_score_4 >= 0.5).int().tolist()  # Predicted labels for positive edges\n",
    "y_pred_neg = (neg_score_4 >= 0.5).int().tolist()  # Predicted labels for negative edges\n",
    "\n",
    "y_pred = y_pred_pos + y_pred_neg  # Combine predicted labels for the test set\n",
    "\n",
    "# Compute confusion matrix\n",
    "cm = confusion_matrix(y_true, y_pred)\n",
    "\n",
    "# Visualize the confusion matrix using seaborn with integer formatting\n",
    "plt.figure(figsize=(6, 6))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', cbar=False, \n",
    "            xticklabels=['Predicted 0', 'Predicted 1'],\n",
    "            yticklabels=['Actual 0', 'Actual 1'])\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "plt.title('Confusion Matrix ML for Shake Comp Algo ML 25p')\n",
    "plt.savefig('cm_ml_shake-comp-algo_25p.png', dpi=200, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "np.save('cm_ml_shake-comp-algo_25.npy', cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics for cm_algo_25.npy:\n",
      "Precision (TP / (TP + FP)): 0.31894484412470026\n",
      "Accuracy (TP / (TP + FP + FN + TN)): 0.00353081722047697\n",
      "False Positive Rate (FP / (TP + FP + FN + TN)): 0.007539489403123756\n",
      "\n",
      "\n",
      "Metrics for cm_algo_shake-comp-algo_25.npy:\n",
      "Precision (TP / (TP + FP)): 0.26476350405821436\n",
      "Accuracy (TP / (TP + FP + FN + TN)): 0.0027904370013126264\n",
      "False Positive Rate (FP / (TP + FP + FN + TN)): 0.007748919664321638\n",
      "\n",
      "\n",
      "Metrics for cm_shake_algo-shake-ml_25.npy:\n",
      "Precision (TP / (TP + FP)): 0.3374769797421731\n",
      "Accuracy (TP / (TP + FP + FN + TN)): 0.0064066146329525495\n",
      "False Positive Rate (FP / (TP + FP + FN + TN)): 0.012577242096614896\n",
      "\n",
      "\n",
      "Metrics for cm_ml_algo-comp-ml_25.npy:\n",
      "Precision (TP / (TP + FP)): 0.22554194156456173\n",
      "Accuracy (TP / (TP + FP + FN + TN)): 0.000884591982410186\n",
      "False Positive Rate (FP / (TP + FP + FN + TN)): 0.00303748111970936\n",
      "\n",
      "\n",
      "Metrics for cm_shake_comp-shake_25.npy:\n",
      "Precision (TP / (TP + FP)): 0.43847874720357943\n",
      "Accuracy (TP / (TP + FP + FN + TN)): 0.0017130920437362887\n",
      "False Positive Rate (FP / (TP + FP + FN + TN)): 0.0021938066478459617\n",
      "\n",
      "\n",
      "Metrics for cm_comp_comp-ml_25.npy:\n",
      "Precision (TP / (TP + FP)): 0.2292887029288703\n",
      "Accuracy (TP / (TP + FP + FN + TN)): 0.0013545915214435793\n",
      "False Positive Rate (FP / (TP + FP + FN + TN)): 0.004553207267334075\n",
      "\n",
      "\n",
      "Metrics for cm_comp_algo-comp-ml_25.npy:\n",
      "Precision (TP / (TP + FP)): 0.22332015810276679\n",
      "Accuracy (TP / (TP + FP + FN + TN)): 0.0016759362254356693\n",
      "False Positive Rate (FP / (TP + FP + FN + TN)): 0.005828698553948832\n",
      "\n",
      "\n",
      "Metrics for cm_algo_comp-algo_25.npy:\n",
      "Precision (TP / (TP + FP)): 0.26117540276832313\n",
      "Accuracy (TP / (TP + FP + FN + TN)): 0.003395130008996652\n",
      "False Positive Rate (FP / (TP + FP + FN + TN)): 0.00960429479521555\n",
      "\n",
      "\n",
      "Metrics for cm_algo_algo-ml_20.npy:\n",
      "Precision (TP / (TP + FP)): 0.24903100775193798\n",
      "Accuracy (TP / (TP + FP + FN + TN)): 0.0030323142043862366\n",
      "False Positive Rate (FP / (TP + FP + FN + TN)): 0.009144138164977951\n",
      "\n",
      "\n",
      "Metrics for cm_ml_comp-ml_25.npy:\n",
      "Precision (TP / (TP + FP)): 0.16680822150501104\n",
      "Accuracy (TP / (TP + FP + FN + TN)): 0.0003630043153893868\n",
      "False Positive Rate (FP / (TP + FP + FN + TN)): 0.0018131732861353792\n",
      "\n",
      "\n",
      "Metrics for cm_algo_algo-shake_25.npy:\n",
      "Precision (TP / (TP + FP)): 0.29967589129892797\n",
      "Accuracy (TP / (TP + FP + FN + TN)): 0.003545565830420483\n",
      "False Positive Rate (FP / (TP + FP + FN + TN)): 0.008285769066265504\n",
      "\n",
      "\n",
      "Metrics for cm_ml_algo-shake-ml_25.npy:\n",
      "Precision (TP / (TP + FP)): 0.16879962634283047\n",
      "Accuracy (TP / (TP + FP + FN + TN)): 0.0006679722992959491\n",
      "False Positive Rate (FP / (TP + FP + FN + TN)): 0.0032892183282431406\n",
      "\n",
      "\n",
      "Metrics for cm_comp_shake-comp-ml_25.npy:\n",
      "Precision (TP / (TP + FP)): 0.1935483870967742\n",
      "Accuracy (TP / (TP + FP + FN + TN)): 0.000682239525398591\n",
      "False Positive Rate (FP / (TP + FP + FN + TN)): 0.002842664689160796\n",
      "\n",
      "\n",
      "Metrics for cm_comp_comp-shake_25.npy:\n",
      "Precision (TP / (TP + FP)): 0.16416184971098266\n",
      "Accuracy (TP / (TP + FP + FN + TN)): 0.0007020145841057965\n",
      "False Positive Rate (FP / (TP + FP + FN + TN)): 0.003574341861327401\n",
      "\n",
      "\n",
      "Metrics for cm_ml_shake-comp-ml_25.npy:\n",
      "Precision (TP / (TP + FP)): 0.24711618503983826\n",
      "Accuracy (TP / (TP + FP + FN + TN)): 0.0007681496612822259\n",
      "False Positive Rate (FP / (TP + FP + FN + TN)): 0.002340305825590843\n",
      "\n",
      "\n",
      "Metrics for cm_comp_shake-comp-algo_25.npy:\n",
      "Precision (TP / (TP + FP)): 0.27552140504939626\n",
      "Accuracy (TP / (TP + FP + FN + TN)): 0.0012408849338771475\n",
      "False Positive Rate (FP / (TP + FP + FN + TN)): 0.003262884686688914\n",
      "\n",
      "\n",
      "Metrics for cm_algo_algo-comp-ml_25.npy:\n",
      "Precision (TP / (TP + FP)): 0.22939362795477902\n",
      "Accuracy (TP / (TP + FP + FN + TN)): 0.0032918897393920624\n",
      "False Positive Rate (FP / (TP + FP + FN + TN)): 0.011058507735645916\n",
      "\n",
      "\n",
      "Metrics for cm_shake_25.npy:\n",
      "Precision (TP / (TP + FP)): 0.3197747183979975\n",
      "Accuracy (TP / (TP + FP + FN + TN)): 0.004466275685455324\n",
      "False Positive Rate (FP / (TP + FP + FN + TN)): 0.00950066863031299\n",
      "\n",
      "\n",
      "Metrics for cm_comp_25.npy:\n",
      "Precision (TP / (TP + FP)): 0.18313253012048192\n",
      "Accuracy (TP / (TP + FP + FN + TN)): 0.0011271783463107155\n",
      "False Positive Rate (FP / (TP + FP + FN + TN)): 0.005027808676307008\n",
      "\n",
      "\n",
      "Metrics for cm_algo_algo-shake-ml_25.npy:\n",
      "Precision (TP / (TP + FP)): 0.2975420439844761\n",
      "Accuracy (TP / (TP + FP + FN + TN)): 0.0027137442296063597\n",
      "False Positive Rate (FP / (TP + FP + FN + TN)): 0.006406796159461971\n",
      "\n",
      "\n",
      "Metrics for cm_ml_algo-ml_20.npy:\n",
      "Precision (TP / (TP + FP)): 0.2270448548812665\n",
      "Accuracy (TP / (TP + FP + FN + TN)): 0.0006361816973372044\n",
      "False Positive Rate (FP / (TP + FP + FN + TN)): 0.0021658271729800586\n",
      "\n",
      "\n",
      "Metrics for cm_ml_25.npy:\n",
      "Precision (TP / (TP + FP)): 0.17624587602014238\n",
      "Accuracy (TP / (TP + FP + FN + TN)): 0.0003752030347456493\n",
      "False Positive Rate (FP / (TP + FP + FN + TN)): 0.0017536583220033107\n",
      "\n",
      "\n",
      "Metrics for cm_ml_shake-comp-algo_25.npy:\n",
      "Precision (TP / (TP + FP)): 0.13147039254823686\n",
      "Accuracy (TP / (TP + FP + FN + TN)): 0.0003652222643632527\n",
      "False Positive Rate (FP / (TP + FP + FN + TN)): 0.002412758825403796\n",
      "\n",
      "\n",
      "Metrics for cm_shake_shake-comp-ml_25.npy:\n",
      "Precision (TP / (TP + FP)): 0.4483747609942639\n",
      "Accuracy (TP / (TP + FP + FN + TN)): 0.004099184533226119\n",
      "False Positive Rate (FP / (TP + FP + FN + TN)): 0.005043133210386932\n",
      "\n",
      "\n",
      "Metrics for cm_shake_shake-comp-algo_25.npy:\n",
      "Precision (TP / (TP + FP)): 0.31742243436754175\n",
      "Accuracy (TP / (TP + FP + FN + TN)): 0.0023249106307849632\n",
      "False Positive Rate (FP / (TP + FP + FN + TN)): 0.004999431882740598\n",
      "\n",
      "\n",
      "Metrics for cm_shake_algo-shake_25.npy:\n",
      "Precision (TP / (TP + FP)): 0.3796240145542753\n",
      "Accuracy (TP / (TP + FP + FN + TN)): 0.005471406221321004\n",
      "False Positive Rate (FP / (TP + FP + FN + TN)): 0.008941291636439915\n",
      "\n",
      "\n",
      "Metrics for cm_comp_comp-algo_25.npy:\n",
      "Precision (TP / (TP + FP)): 0.22941176470588234\n",
      "Accuracy (TP / (TP + FP + FN + TN)): 0.0017352614015572858\n",
      "False Positive Rate (FP / (TP + FP + FN + TN)): 0.005828698553948832\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "\n",
    "# Define the path to the folder containing the numpy files (confusion matrices)\n",
    "npy_folder = 'New_25_Percent/CM_NPY'\n",
    "\n",
    "# List all the numpy files in the folder\n",
    "npy_files = [f for f in os.listdir(npy_folder) if f.endswith('.npy')]\n",
    "\n",
    "# Loop through each numpy file and calculate the required metrics\n",
    "for npy_file in npy_files:\n",
    "    # Load the confusion matrix from the numpy file\n",
    "    npy_path = os.path.join(npy_folder, npy_file)\n",
    "    cm = np.load(npy_path)\n",
    "    \n",
    "    # Extract the values from the confusion matrix\n",
    "    tn = cm[0, 0]  # Top-left: True Negative (TN)\n",
    "    fp = cm[0, 1]  # Top-right: False Positive (FP)\n",
    "    fn = cm[1, 0]  # Bottom-left: False Negative (FN)\n",
    "    tp = cm[1, 1]  # Bottom-right: True Positive (TP)\n",
    "\n",
    "\n",
    "    # Calculate the metrics\n",
    "    precision = tp / (tp + fp) if (tp + fp) > 0 else 0  # Precision: TP / (TP + FP)\n",
    "    total_accuracy = tp / (tp + fp + fn + tn) if (tp + fp + fn + tn) > 0 else 0  # TP / (TP + FP + FN + TN)\n",
    "    false_positive_rate = fp / (tp + fp + fn + tn) if (tp + fp + fn + tn) > 0 else 0  # FP / (TP + FP + FN + TN)\n",
    "\n",
    "    # Print or store the results\n",
    "    print(f\"Metrics for {npy_file}:\")\n",
    "    print(f\"Precision (TP / (TP + FP)): {precision}\")\n",
    "    print(f\"Accuracy (TP / (TP + FP + FN + TN)): {total_accuracy}\")\n",
    "    print(f\"False Positive Rate (FP / (TP + FP + FN + TN)): {false_positive_rate}\")\n",
    "    print(\"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moved model_comp-shake_25p.pth to New_25_Percent/Models\n",
      "Moved model_algo_25p.pth to New_25_Percent/Models\n",
      "Moved model_algo-comp-ml_25p.pth to New_25_Percent/Models\n",
      "Moved model_algo-shake_25p.pth to New_25_Percent/Models\n",
      "Moved model_comp-ml_25p.pth to New_25_Percent/Models\n",
      "Moved model_shake-comp-ml_25p.pth to New_25_Percent/Models\n",
      "Moved model_shake-ml_25p.pth to New_25_Percent/Models\n",
      "Moved model_algo-shake-ml_25p.pth to New_25_Percent/Models\n",
      "Moved model_shake-comp-algo-ml_25p.pth to New_25_Percent/Models\n",
      "Moved model_shake_25p.pth to New_25_Percent/Models\n",
      "Moved model_shake-comp-algo_25p.pth to New_25_Percent/Models\n",
      "Moved model_comp_25p.pth to New_25_Percent/Models\n",
      "Moved model_ml_25p.pth to New_25_Percent/Models\n",
      "Moved model_comp-algo_25p.pth to New_25_Percent/Models\n",
      "Moved model_algo-ml_25p.pth to New_25_Percent/Models\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import shutil\n",
    "\n",
    "# Define the source directory (where the .png files are located)\n",
    "source_dir = '.'  # Use '.' for current directory or specify another folder path\n",
    "\n",
    "# Define the destination directory\n",
    "destination_dir = 'New_25_Percent/Models'\n",
    "\n",
    "# Create the destination directory if it doesn't exist\n",
    "if not os.path.exists(destination_dir):\n",
    "    os.makedirs(destination_dir)\n",
    "\n",
    "# Move all .png files from source_dir to destination_dir\n",
    "for filename in os.listdir(source_dir):\n",
    "    if filename.endswith('.pth'):\n",
    "        # Construct the full file path\n",
    "        source_file = os.path.join(source_dir, filename)\n",
    "        destination_file = os.path.join(destination_dir, filename)\n",
    "        \n",
    "        # Move the file\n",
    "        shutil.move(source_file, destination_file)\n",
    "        print(f\"Moved {filename} to {destination_dir}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (GNN_venv)",
   "language": "python",
   "name": "gnn_venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
