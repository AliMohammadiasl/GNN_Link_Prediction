{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"mount_file_id":"1UmInx_Y585GWf9mZcpsFxiXkq2kl089q","authorship_tag":"ABX9TyPoQKpwV6olYFYeaKTCNAD5"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["## Calculating the metrics"],"metadata":{"id":"xPhPPm3rAJcM"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"qMyUTzOxACM0"},"outputs":[],"source":["import numpy as np\n","import pandas as pd\n","import os\n","\n","# Define datasets, seeds, percentages, and combinations\n","datasets = ['algo004', 'comp', 'ml', 'virtualshakespeare']\n","seeds = [18, 61, 53, 29, 69, 42, 2, 21, 78, 99]\n","percentages = [0.05, 0.1, 0.15, 0.2, 0.25, 0.5, 0.75]\n","combinations = [\n","    ['algo004', 'comp'],\n","    ['algo004', 'ml'],\n","    ['algo004', 'virtualshakespeare'],\n","    ['comp', 'ml'],\n","    ['comp', 'virtualshakespeare'],\n","    ['ml', 'virtualshakespeare'],\n","    ['algo004', 'comp', 'ml'],\n","    ['algo004', 'comp', 'virtualshakespeare'],\n","    ['algo004', 'ml', 'virtualshakespeare'],\n","    ['comp', 'ml', 'virtualshakespeare'],\n","    ['algo004', 'comp', 'ml', 'virtualshakespeare']\n","]\n","\n","# Function to calculate metrics from confusion matrix\n","def calculate_metrics(cm):\n","    tn, fp, fn, tp = cm.ravel()\n","    total_samples = tn + fp + fn + tp\n","    # Precision\n","    precision = tp / (tp + fp) if (tp + fp) > 0 else 0\n","    # True Positives divided by all samples\n","    tp_div_all = tp / total_samples\n","    # False Positives divided by all samples\n","    fp_div_all = fp / total_samples\n","    return precision, tp_div_all, fp_div_all\n","\n","# Main processing\n","for seed in seeds:\n","    for percentage in percentages:\n","        percentage_str = f'{percentage}p'  # Convert to string with 'p' suffix\n","        for ds in datasets:\n","            # Initialize a list to collect results for this dataset, seed, and percentage\n","            results = []\n","            # First, collect the individual dataset's metrics\n","            base_dir = f'/content/drive/MyDrive/Colab Notebooks/Fed Learning Research/{ds}_results'\n","            cm_npy_dir = os.path.join(base_dir, 'cm_npy', str(seed))\n","            cm_filename = f'cm_{ds}_{percentage_str}_seed{seed}.npy'\n","            cm_path = os.path.join(cm_npy_dir, cm_filename)\n","            if os.path.exists(cm_path):\n","                cm = np.load(cm_path)\n","                precision, tp_div_all, fp_div_all = calculate_metrics(cm)\n","                result = {\n","                    'Dataset': ds,\n","                    'Combination': ds,\n","                    'Percentage': percentage,\n","                    'Seed': seed,\n","                    'Precision': precision,\n","                    'TP_div_all': tp_div_all,\n","                    'FP_div_all': fp_div_all\n","                }\n","                results.append(result)\n","            else:\n","                print(f'Confusion matrix not found for {ds} at {percentage}% seed {seed}')\n","\n","            # Now, collect metrics for combinations that include this dataset\n","            for combo in combinations:\n","                if ds in combo:\n","                    combo_name = '_'.join(combo)\n","                    cm_npy_dir = f'/content/drive/MyDrive/Colab Notebooks/Fed Learning Research/combined_results/cm_npy/npy_{percentage}/{seed}'\n","                    cm_filename = f'cm_{ds}_{combo_name}_{percentage_str}_seed{seed}.npy'\n","                    cm_path = os.path.join(cm_npy_dir, cm_filename)\n","                    if os.path.exists(cm_path):\n","                        cm = np.load(cm_path)\n","                        precision, tp_div_all, fp_div_all = calculate_metrics(cm)\n","                        result = {\n","                            'Dataset': ds,\n","                            'Combination': combo_name,\n","                            'Percentage': percentage,\n","                            'Seed': seed,\n","                            'Precision': precision,\n","                            'TP_div_all': tp_div_all,\n","                            'FP_div_all': fp_div_all\n","                        }\n","                        results.append(result)\n","                    else:\n","                        print(f'Confusion matrix not found for {ds} in combination {combo_name} at {percentage}% seed {seed}')\n","\n","            # Save the collected results into a CSV file\n","            if results:\n","                results_df = pd.DataFrame(results)\n","                # Define the save path\n","                csv_dir = f'/content/drive/MyDrive/Colab Notebooks/Fed Learning Research/{ds}_results/csv/combined_results'\n","                os.makedirs(csv_dir, exist_ok=True)\n","                csv_filename = f'metrics_{ds}_seed{seed}_{percentage_str}.csv'\n","                csv_save_path = os.path.join(csv_dir, csv_filename)\n","                results_df.to_csv(csv_save_path, index=False)\n","            else:\n","                print(f'No results to save for {ds} at {percentage}% seed {seed}')\n"]},{"cell_type":"markdown","source":["## Metrics with differences"],"metadata":{"id":"9tbijclIAOX9"}},{"cell_type":"code","source":["import numpy as np\n","import pandas as pd\n","import os\n","\n","# Define datasets, seeds, percentages, and combinations\n","datasets = ['algo004', 'comp', 'ml', 'virtualshakespeare']\n","seeds = [18, 61, 53, 29, 69, 42, 2, 21, 78, 99]\n","percentages = [0.05, 0.1, 0.15, 0.2, 0.25, 0.5, 0.75]\n","combinations = [\n","    ['algo004', 'comp'],\n","    ['algo004', 'ml'],\n","    ['algo004', 'virtualshakespeare'],\n","    ['comp', 'ml'],\n","    ['comp', 'virtualshakespeare'],\n","    ['ml', 'virtualshakespeare'],\n","    ['algo004', 'comp', 'ml'],\n","    ['algo004', 'comp', 'virtualshakespeare'],\n","    ['algo004', 'ml', 'virtualshakespeare'],\n","    ['comp', 'ml', 'virtualshakespeare'],\n","    ['algo004', 'comp', 'ml', 'virtualshakespeare']\n","]\n","\n","# Function to calculate metrics from confusion matrix\n","def calculate_metrics(cm):\n","    tn, fp, fn, tp = cm.ravel()\n","    total_samples = tn + fp + fn + tp\n","    # Precision\n","    precision = tp / (tp + fp) if (tp + fp) > 0 else 0\n","    # True Positives divided by all samples\n","    tp_div_all = tp / total_samples\n","    # False Positives divided by all samples\n","    fp_div_all = fp / total_samples\n","    return precision, tp_div_all, fp_div_all\n","\n","# Main processing\n","for seed in seeds:\n","    for percentage in percentages:\n","        percentage_str = f'{percentage}p'  # Convert to string with 'p' suffix\n","        for ds in datasets:\n","            # Initialize a list to collect results for this dataset, seed, and percentage\n","            results = []\n","            # First, collect the individual dataset's metrics\n","            base_dir = f'/content/drive/MyDrive/Colab Notebooks/Fed Learning Research/{ds}_results'\n","            cm_npy_dir = os.path.join(base_dir, 'cm_npy', str(seed))\n","            cm_filename = f'cm_{ds}_{percentage_str}_seed{seed}.npy'\n","            cm_path = os.path.join(cm_npy_dir, cm_filename)\n","            if os.path.exists(cm_path):\n","                cm = np.load(cm_path)\n","                precision, tp_div_all, fp_div_all = calculate_metrics(cm)\n","                result = {\n","                    'Dataset': ds,\n","                    'Combination': ds,\n","                    'Percentage': percentage,\n","                    'Seed': seed,\n","                    'Precision': precision,\n","                    'TP_div_all': tp_div_all,\n","                    'FP_div_all': fp_div_all\n","                }\n","                results.append(result)\n","            else:\n","                print(f'Confusion matrix not found for {ds} at {percentage}% seed {seed}')\n","\n","            # Now, collect metrics for combinations that include this dataset\n","            for combo in combinations:\n","                if ds in combo:\n","                    combo_name = '_'.join(combo)\n","                    cm_npy_dir = f'/content/drive/MyDrive/Colab Notebooks/Fed Learning Research/combined_results/cm_npy/npy_{percentage}/{seed}'\n","                    cm_filename = f'cm_{ds}_{combo_name}_{percentage_str}_seed{seed}.npy'\n","                    cm_path = os.path.join(cm_npy_dir, cm_filename)\n","                    if os.path.exists(cm_path):\n","                        cm = np.load(cm_path)\n","                        precision, tp_div_all, fp_div_all = calculate_metrics(cm)\n","                        result = {\n","                            'Dataset': ds,\n","                            'Combination': combo_name,\n","                            'Percentage': percentage,\n","                            'Seed': seed,\n","                            'Precision': precision,\n","                            'TP_div_all': tp_div_all,\n","                            'FP_div_all': fp_div_all\n","                        }\n","                        results.append(result)\n","                    else:\n","                        print(f'Confusion matrix not found for {ds} in combination {combo_name} at {percentage}% seed {seed}')\n","\n","            # Save the collected results into a CSV file\n","            if results:\n","                results_df = pd.DataFrame(results)\n","\n","                # Ensure that the individual dataset's metrics are first\n","                results_df = results_df.sort_values(by='Combination', key=lambda x: x.apply(lambda y: (0, y) if y == ds else (1, y)))\n","\n","                # Get baseline metrics from the first row (individual dataset)\n","                base_precision = results_df.iloc[0]['Precision']\n","                base_tp_div_all = results_df.iloc[0]['TP_div_all']\n","                base_fp_div_all = results_df.iloc[0]['FP_div_all']\n","\n","                # Compute differences\n","                results_df['Precision_Difference'] = results_df['Precision'] - base_precision\n","                results_df['TP_div_all_Difference'] = results_df['TP_div_all'] - base_tp_div_all\n","                results_df['FP_div_all_Difference'] = results_df['FP_div_all'] - base_fp_div_all\n","\n","                # Define the save path\n","                csv_dir = f'/content/drive/MyDrive/Colab Notebooks/Fed Learning Research/{ds}_results/csv/combined_csv'\n","                os.makedirs(csv_dir, exist_ok=True)\n","                csv_filename = f'metrics_{ds}_seed{seed}_{percentage_str}.csv'\n","                csv_save_path = os.path.join(csv_dir, csv_filename)\n","                results_df.to_csv(csv_save_path, index=False)\n","                print(f'Saved metrics for {ds} at {percentage_str} for seed {seed} to {csv_save_path}')\n","            else:\n","                print(f'No results to save for {ds} at {percentage}% seed {seed}')\n"],"metadata":{"id":"Ep56CzRkATvh"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Generating graphs from differences"],"metadata":{"id":"4vFdu9RgAVw4"}},{"cell_type":"code","source":["!ls"],"metadata":{"id":"MW5E1YWPEMOy"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Charts for Precision difference"],"metadata":{"id":"TbUN93ANrKhX"}},{"cell_type":"code","source":["import pandas as pd\n","import matplotlib.pyplot as plt\n","import os\n","\n","# Define datasets, seeds, percentages\n","datasets = ['algo004', 'comp', 'ml', 'virtualshakespeare']\n","seeds = [18, 61, 53, 29, 69, 42, 2, 21, 78, 99]\n","percentages = [0.05, 0.1, 0.15, 0.2, 0.25, 0.5, 0.75]  # percentages as integers\n","\n","# Define difference metrics\n","difference_metrics = ['Precision_Difference', 'TP_div_all_Difference', 'FP_div_all_Difference']\n","\n","# Define colors\n","positive_color = 'blue'\n","negative_color = 'red'\n","\n","# Parent directory for charts\n","charts_parent_dir = '/content/drive/MyDrive/Colab Notebooks/GNN Research/charts'\n","\n","# Main processing\n","for ds in datasets:\n","    for seed in seeds:\n","        for percentage in percentages:\n","            # Construct percentage string\n","            percentage_str = f'{percentage}p'\n","            # Path to the CSV file\n","            csv_file = f'/content/drive/MyDrive/Colab Notebooks/GNN Research/{ds}_results/csv/combined_csv/metrics_{ds}_seed{seed}_{percentage_str}.csv'\n","            # Check if the CSV file exists\n","            if not os.path.exists(csv_file):\n","                print(f'CSV file not found: {csv_file}')\n","                continue\n","            # Read the CSV file\n","            df = pd.read_csv(csv_file)\n","            # Skip if there are no combinations (less than 2 rows)\n","            if df.shape[0] <= 1:\n","                print(f'Not enough data to plot for {ds}, seed {seed}, percentage {percentage}')\n","                continue\n","            # For each difference metric, create a chart\n","            for metric in difference_metrics:\n","                # Prepare data\n","                combinations = df['Combination'][1:]  # Exclude the first row (individual dataset)\n","                differences = df[metric][1:]  # Exclude the first row (individual dataset)\n","                # Convert combinations and differences to lists\n","                combinations = combinations.tolist()\n","                differences = differences.tolist()\n","                # Create a color list based on positive or negative differences\n","                colors = [positive_color if x >= 0 else negative_color for x in differences]\n","                # Create the plot\n","                plt.figure(figsize=(10, len(combinations)*0.5))\n","                # Plot horizontal bars\n","                plt.barh(combinations, differences, color=colors)\n","                # Add vertical line at x=0\n","                plt.axvline(x=0, color='black', linewidth=0.8)\n","                # Set labels and title\n","                plt.xlabel(metric.replace('_', ' '))\n","                plt.ylabel('Combination')\n","                plt.title(f'{metric.replace(\"_\", \" \")} for {ds} (Seed {seed}, {percentage}%)')\n","                plt.tight_layout()\n","                # Define the save path\n","                chart_dir = os.path.join(charts_parent_dir, ds, f'seed_{seed}', f'{percentage}p')\n","                os.makedirs(chart_dir, exist_ok=True)\n","                # Name the file as per your specification\n","                metric_name = metric.replace('_Difference', '').replace('_', '')\n","                for idx, combination in enumerate(combinations):\n","                    # Prepare data for single combination\n","                    diff = differences[idx]\n","                    color = colors[idx]\n","                    # Create a single-bar plot\n","                    plt.figure(figsize=(6, 1))\n","                    plt.barh([combination], [diff], color=color)\n","                    plt.axvline(x=0, color='black', linewidth=0.8)\n","                    plt.xlabel(metric_name)\n","                    plt.title(f'{metric_name} Difference for {ds} with {combination}\\n(Seed {seed}, {percentage}%)')\n","                    plt.tight_layout()\n","                    # Filename: dataset_combination_percent_seed_metric.png\n","                    chart_filename = f'{ds}_{combination}_{percentage}p_seed{seed}_{metric_name}.png'\n","                    chart_save_path = os.path.join(chart_dir, chart_filename)\n","                    # Save the plot\n","                    plt.savefig(chart_save_path, dpi=200)\n","                    plt.close()\n","                    #print(f'Saved chart: {chart_save_path}')\n","                # Comment out the group plot if you prefer individual charts per combination\n","                plt.savefig(chart_save_path, dpi=200)\n","                plt.close()\n","                print(f'Saved chart: {chart_save_path}')\n"],"metadata":{"id":"WVJUlnUYAVRE"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Calculating AUC mean, ACC mean, Precision mean, and standard deviation"],"metadata":{"id":"SkmcUN136OtM"}},{"cell_type":"code","source":["import numpy as np\n","import pandas as pd\n","import os\n","\n","# Define datasets, seeds, percentages, and combinations\n","datasets = ['algo004', 'comp', 'ml', 'virtualshakespeare']\n","seeds = [18, 61, 53, 29, 69, 42, 2, 21, 78, 99]\n","percentages = [0.05, 0.1, 0.15, 0.2, 0.25, 0.5, 0.75]\n","combinations = [\n","    ['algo004', 'comp'],\n","    ['algo004', 'ml'],\n","    ['algo004', 'virtualshakespeare'],\n","    ['comp', 'ml'],\n","    ['comp', 'virtualshakespeare'],\n","    ['ml', 'virtualshakespeare'],\n","    ['algo004', 'comp', 'ml'],\n","    ['algo004', 'comp', 'virtualshakespeare'],\n","    ['algo004', 'ml', 'virtualshakespeare'],\n","    ['comp', 'ml', 'virtualshakespeare'],\n","    ['algo004', 'comp', 'ml', 'virtualshakespeare']\n","]\n","\n","# Function to calculate metrics from confusion matrix\n","def calculate_metrics(cm):\n","    tn, fp, fn, tp = cm.ravel()\n","    total_samples = tn + fp + fn + tp\n","    # Precision\n","    precision = tp / (tp + fp) if (tp + fp) > 0 else 0\n","    # Accuracy\n","    accuracy = (tp + tn) / total_samples if total_samples > 0 else 0\n","    return precision, accuracy\n","\n","# Main processing\n","for ds in datasets:\n","    for percentage in percentages:\n","        percentage_str = f'{percentage}p'  # Convert to string with 'p' suffix\n","        # Get combinations that include the current dataset\n","        ds_combinations = [combo for combo in combinations if ds in combo]\n","        # Include the individual dataset\n","        ds_combinations.insert(0, [ds])\n","        # Initialize a list to collect mean metrics for each combination\n","        results = []\n","        for combo in ds_combinations:\n","            combo_name = '_'.join(combo)\n","            precisions = []\n","            accuracies = []\n","            aucs = []\n","            for seed in seeds:\n","                # Load confusion matrix\n","                if len(combo) == 1:\n","                    # Individual dataset\n","                    base_dir = f'/content/drive/MyDrive/Colab Notebooks/GNN Research/{ds}_results'\n","                    cm_npy_dir = os.path.join(base_dir, 'cm_npy', str(seed))\n","                    cm_filename = f'cm_{ds}_{percentage_str}_seed{seed}.npy'\n","                    cm_path = os.path.join(cm_npy_dir, cm_filename)\n","                else:\n","                    # Combination\n","                    cm_npy_dir = f'/content/drive/MyDrive/Colab Notebooks/GNN Research/combined_results/cm_npy/npy_{percentage}/{seed}'\n","                    cm_filename = f'cm_{ds}_{combo_name}_{percentage_str}_seed{seed}.npy'\n","                    cm_path = os.path.join(cm_npy_dir, cm_filename)\n","                if os.path.exists(cm_path):\n","                    cm = np.load(cm_path)\n","                    precision, accuracy = calculate_metrics(cm)\n","                    precisions.append(precision)\n","                    accuracies.append(accuracy)\n","                else:\n","                    print(f'Confusion matrix not found for {ds} in combination {combo_name} at {percentage*100}% seed {seed}')\n","                    continue\n","                # Try to load AUC value\n","                if len(combo) == 1:\n","                    # Individual dataset\n","                    csv_dir = f'/content/drive/MyDrive/Colab Notebooks/GNN Research/{ds}_results/csv/{seed}'\n","                    csv_filename = f'results_{ds}_{percentage_str}_seed{seed}.csv'\n","                    csv_path = os.path.join(csv_dir, csv_filename)\n","                else:\n","                    # Combination\n","                    csv_dir = f'/content/drive/MyDrive/Colab Notebooks/GNN Research/combined_results/csv/csv_{percentage}/{seed}'\n","                    csv_filename = f'Combined_{combo_name}_{percentage_str}_seed{seed}.csv'\n","                    csv_path = os.path.join(csv_dir, csv_filename)\n","                if os.path.exists(csv_path):\n","                    df = pd.read_csv(csv_path)\n","                    # Modify this part to filter the DataFrame based on 'Dataset' and 'AUC'\n","                    # Check if 'Dataset' column exists\n","                    if 'Dataset' in df.columns:\n","                        # Filter the DataFrame to get the row matching the specific dataset\n","                        filtered_df = df[df['Dataset'] == ds]\n","                        if not filtered_df.empty:\n","                            auc = filtered_df['AUC'].values[0]\n","                            aucs.append(auc)\n","                        else:\n","                            print(f'AUC value not found for dataset {ds} in CSV file {csv_path}')\n","                    else:\n","                        # If 'Dataset' column does not exist, handle accordingly\n","                        # Assuming the CSV only contains AUC values for the combination\n","                        # and the 'AUC' value corresponds to the combination\n","                        auc = df['AUC'].values[0]\n","                        aucs.append(auc)\n","                else:\n","                    print(f'AUC file not found for {ds} in combination {combo_name} at {percentage*100}% seed {seed}')\n","            # Compute mean metrics\n","            mean_precision = np.mean(precisions) if precisions else None\n","            mean_accuracy = np.mean(accuracies) if accuracies else None\n","            mean_auc = np.mean(aucs) if aucs else None\n","            result = {\n","                'Dataset': ds,\n","                'Combination': combo_name,\n","                'Percentage': percentage,\n","                'Mean_Precision': mean_precision,\n","                'Mean_Accuracy': mean_accuracy,\n","                'Mean_AUC': mean_auc\n","            }\n","            results.append(result)\n","        # Save the collected mean results into a CSV file\n","        if results:\n","            results_df = pd.DataFrame(results)\n","            # Define the save path\n","            csv_dir = f'/content/drive/MyDrive/Colab Notebooks/GNN Research/mean_results/{ds}'\n","            os.makedirs(csv_dir, exist_ok=True)\n","            csv_filename = f'mean_metrics_{ds}_{percentage_str}.csv'\n","            csv_save_path = os.path.join(csv_dir, csv_filename)\n","            results_df.to_csv(csv_save_path, index=False)\n","        else:\n","            print(f'No results to save for {ds} at {percentage*100}%')\n"],"metadata":{"id":"xouDbwWR6NkL"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import numpy as np\n","import pandas as pd\n","import os\n","\n","# Define datasets, seeds, percentages, and combinations\n","datasets = ['algo004', 'comp', 'ml', 'virtualshakespeare']\n","seeds = [18, 61, 53, 29, 69, 42, 2, 21, 78, 99]\n","percentages = [0.05, 0.1, 0.15, 0.2, 0.25, 0.5, 0.75]\n","combinations = [\n","    ['algo004', 'comp'],\n","    ['algo004', 'ml'],\n","    ['algo004', 'virtualshakespeare'],\n","    ['comp', 'ml'],\n","    ['comp', 'virtualshakespeare'],\n","    ['ml', 'virtualshakespeare'],\n","    ['algo004', 'comp', 'ml'],\n","    ['algo004', 'comp', 'virtualshakespeare'],\n","    ['algo004', 'ml', 'virtualshakespeare'],\n","    ['comp', 'ml', 'virtualshakespeare'],\n","    ['algo004', 'comp', 'ml', 'virtualshakespeare']\n","]\n","\n","# Function to calculate metrics from confusion matrix\n","def calculate_metrics(cm):\n","    tn, fp, fn, tp = cm.ravel()\n","    total_samples = tn + fp + fn + tp\n","    # Precision\n","    precision = tp / (tp + fp) if (tp + fp) > 0 else 0\n","    # Accuracy\n","    accuracy = (tp + tn) / total_samples if total_samples > 0 else 0\n","    return precision, accuracy\n","\n","# Main processing\n","for ds in datasets:\n","    for percentage in percentages:\n","        percentage_str = f'{percentage}p'  # Convert to string with 'p' suffix\n","        # Get combinations that include the current dataset\n","        ds_combinations = [combo for combo in combinations if ds in combo]\n","        # Include the individual dataset\n","        ds_combinations.insert(0, [ds])\n","        # Initialize a list to collect mean and std metrics for each combination\n","        results = []\n","        for combo in ds_combinations:\n","            combo_name = '_'.join(combo)\n","            precisions = []\n","            accuracies = []\n","            aucs = []\n","            for seed in seeds:\n","                # Load confusion matrix\n","                if len(combo) == 1:\n","                    # Individual dataset\n","                    base_dir = f'/content/drive/MyDrive/Colab Notebooks/GNN Research/{ds}_results'\n","                    cm_npy_dir = os.path.join(base_dir, 'cm_npy', str(seed))\n","                    cm_filename = f'cm_{ds}_{percentage_str}_seed{seed}.npy'\n","                    cm_path = os.path.join(cm_npy_dir, cm_filename)\n","                else:\n","                    # Combination\n","                    cm_npy_dir = f'/content/drive/MyDrive/Colab Notebooks/GNN Research/combined_results/cm_npy/npy_{percentage}/{seed}'\n","                    cm_filename = f'cm_{ds}_{combo_name}_{percentage_str}_seed{seed}.npy'\n","                    cm_path = os.path.join(cm_npy_dir, cm_filename)\n","                if os.path.exists(cm_path):\n","                    cm = np.load(cm_path)\n","                    precision, accuracy = calculate_metrics(cm)\n","                    precisions.append(precision)\n","                    accuracies.append(accuracy)\n","                else:\n","                    print(f'Confusion matrix not found for {ds} in combination {combo_name} at {percentage*100}% seed {seed}')\n","                    continue\n","                # Try to load AUC value\n","                if len(combo) == 1:\n","                    # Individual dataset\n","                    csv_dir = f'/content/drive/MyDrive/Colab Notebooks/GNN Research/{ds}_results/csv/{seed}'\n","                    csv_filename = f'results_{ds}_{percentage_str}_seed{seed}.csv'\n","                    csv_path = os.path.join(csv_dir, csv_filename)\n","                else:\n","                    # Combination\n","                    csv_dir = f'/content/drive/MyDrive/Colab Notebooks/GNN Research/combined_results/csv/csv_{percentage}/{seed}'\n","                    csv_filename = f'Combined_{combo_name}_{percentage_str}_seed{seed}.csv'\n","                    csv_path = os.path.join(csv_dir, csv_filename)\n","                if os.path.exists(csv_path):\n","                    df = pd.read_csv(csv_path)\n","                    # Modify this part to filter the DataFrame based on 'Dataset' and 'AUC'\n","                    # Check if 'Dataset' column exists\n","                    if 'Dataset' in df.columns:\n","                        # Filter the DataFrame to get the row matching the specific dataset\n","                        filtered_df = df[df['Dataset'] == ds]\n","                        if not filtered_df.empty:\n","                            auc = filtered_df['AUC'].values[0]\n","                            aucs.append(auc)\n","                        else:\n","                            print(f'AUC value not found for dataset {ds} in CSV file {csv_path}')\n","                    else:\n","                        # If 'Dataset' column does not exist, handle accordingly\n","                        # Assuming the CSV only contains AUC values for the combination\n","                        # and the 'AUC' value corresponds to the combination\n","                        auc = df['AUC'].values[0]\n","                        aucs.append(auc)\n","                else:\n","                    print(f'AUC file not found for {ds} in combination {combo_name} at {percentage*100}% seed {seed}')\n","            # Compute mean and standard deviation metrics\n","            mean_precision = np.mean(precisions) if precisions else None\n","            mean_accuracy = np.mean(accuracies) if accuracies else None\n","            mean_auc = np.mean(aucs) if aucs else None\n","\n","            std_precision = np.std(precisions, ddof=1) if len(precisions) > 1 else None\n","            std_accuracy = np.std(accuracies, ddof=1) if len(accuracies) > 1 else None\n","            std_auc = np.std(aucs, ddof=1) if len(aucs) > 1 else None\n","\n","            result = {\n","                'Dataset': ds,\n","                'Combination': combo_name,\n","                'Percentage': percentage,\n","                'Mean_Precision': mean_precision,\n","                'Std_Precision': std_precision,\n","                'Mean_Accuracy': mean_accuracy,\n","                'Std_Accuracy': std_accuracy,\n","                'Mean_AUC': mean_auc,\n","                'Std_AUC': std_auc\n","            }\n","            results.append(result)\n","        # Save the collected mean and std results into a CSV file\n","        if results:\n","            results_df = pd.DataFrame(results)\n","            # Define the save path\n","            csv_dir = f'/content/drive/MyDrive/Colab Notebooks/GNN Research/mean_results/{ds}'\n","            os.makedirs(csv_dir, exist_ok=True)\n","            csv_filename = f'mean_metrics_{ds}_{percentage_str}.csv'\n","            csv_save_path = os.path.join(csv_dir, csv_filename)\n","            results_df.to_csv(csv_save_path, index=False)\n","            print(f'Saved mean and std metrics for {ds} at {percentage}%')\n","        else:\n","            print(f'No results to save for {ds} at {percentage*100}%')\n"],"metadata":{"id":"XyRo5oDKwXBp"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Plot the means for comparison"],"metadata":{"id":"Bf6IB5jcsKvD"}},{"cell_type":"code","source":["import pandas as pd\n","import matplotlib.pyplot as plt\n","import os\n","\n","# Define datasets and percentages\n","datasets = ['algo004', 'comp', 'ml', 'virtualshakespeare']\n","percentages = [0.05, 0.1, 0.15, 0.2, 0.25, 0.5, 0.75]  # percentages as integers\n","\n","# Define metrics to plot and their corresponding colors\n","metrics_info = {\n","    'Mean_AUC': {'label': 'Mean AUC', 'color': 'blue'},\n","    'Mean_Accuracy': {'label': 'Mean Accuracy', 'color': 'green'},\n","    'Mean_Precision': {'label': 'Mean Precision', 'color': 'purple'},\n","}\n","\n","# Parent directories for mean results and charts\n","mean_results_dir = '/content/drive/MyDrive/Colab Notebooks/GNN Research/mean_results'\n","charts_dir = '/content/drive/MyDrive/Colab Notebooks/GNN Research/mean_charts'\n","\n","# Create charts directory if it doesn't exist\n","os.makedirs(charts_dir, exist_ok=True)\n","\n","# Loop through datasets and percentages\n","for ds in datasets:\n","    for percentage in percentages:\n","        percentage_str = f'{percentage}p'\n","        # Path to the mean metrics CSV file\n","        csv_file = os.path.join(mean_results_dir, ds, f'mean_metrics_{ds}_{percentage_str}.csv')\n","        # Check if the CSV file exists\n","        if not os.path.exists(csv_file):\n","            print(f'CSV file not found: {csv_file}')\n","            continue\n","        # Read the CSV file\n","        df = pd.read_csv(csv_file)\n","        # Skip if the DataFrame is empty\n","        if df.empty:\n","            print(f'No data to plot for {ds} at {percentage}%')\n","            continue\n","        # Create a separate folder for this dataset and percentage\n","        plot_save_dir = os.path.join(charts_dir, ds, percentage_str)\n","        os.makedirs(plot_save_dir, exist_ok=True)\n","        # For each metric, create a bar chart\n","        for metric, info in metrics_info.items():\n","            # Prepare data\n","            combinations = df['Combination']\n","            values = df[metric]\n","            # Skip if all values are NaN\n","            if values.isnull().all():\n","                print(f'All values are NaN for {metric} in {ds} at {percentage}%')\n","                continue\n","            # Create the plot\n","            plt.figure(figsize=(12, 6))\n","            plt.bar(combinations, values, color=info['color'])\n","            # Add value labels on top of the bars\n","            for i, v in enumerate(values):\n","                if pd.notnull(v):\n","                    plt.text(i, v + 0.005, f'{v:.3f}', ha='center', va='bottom', fontsize=9)\n","            # Set labels and title\n","            plt.xlabel('Combination', fontsize=12)\n","            plt.ylabel(info['label'], fontsize=12)\n","            plt.title(f'{info[\"label\"]} for {ds} at {percentage}%', fontsize=14)\n","            plt.xticks(rotation=45, ha='right', fontsize=10)\n","            plt.yticks(fontsize=10)\n","            plt.tight_layout()\n","            # Define the save path\n","            plot_filename = f'{ds}_{percentage_str}_{metric}.png'\n","            plot_save_full_path = os.path.join(plot_save_dir, plot_filename)\n","            # Save the plot\n","            plt.savefig(plot_save_full_path, dpi=200)\n","            plt.close()\n","            print(f'Saved plot: {plot_save_full_path}')\n"],"metadata":{"id":"J5L30cyFuMT7"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Hypothesis Testing"],"metadata":{"id":"2KX7OvKDjVPl"}},{"cell_type":"code","source":["import os\n","import numpy as np\n","import pandas as pd\n","from scipy import stats\n","\n","# Define datasets, percentages, and combinations\n","datasets = ['algo004', 'comp', 'ml', 'virtualshakespeare']\n","percentages = [0.05, 0.1, 0.15, 0.2, 0.25, 0.5, 0.75]  # percentages as integers\n","num_seeds = 10  # Number of seeds used in your experiments\n","\n","# Significance level\n","alpha = 0.05  # You can adjust this value as needed\n","\n","# Directories\n","base_dir = '/content/drive/MyDrive/Colab Notebooks/GNN Research'\n","mean_results_dir = os.path.join(base_dir, 'mean_results')\n","hypothesis_testing_dir = os.path.join(base_dir, 'hypothesis_testing')\n","os.makedirs(hypothesis_testing_dir, exist_ok=True)\n","\n","# Perform hypothesis testing\n","for ds in datasets:\n","    # Create a directory for the dataset\n","    ds_hypothesis_dir = os.path.join(hypothesis_testing_dir, ds)\n","    os.makedirs(ds_hypothesis_dir, exist_ok=True)\n","\n","    for percentage in percentages:\n","        percentage_str = f'{percentage}p'\n","\n","        # Path to the mean metrics CSV for this dataset and percentage\n","        mean_csv_path = os.path.join(mean_results_dir, ds, f'mean_metrics_{ds}_{percentage_str}.csv')\n","\n","        if not os.path.exists(mean_csv_path):\n","            print(f'Mean metrics CSV not found for {ds} at {percentage}%')\n","            continue\n","\n","        # Load the mean metrics\n","        mean_df = pd.read_csv(mean_csv_path)\n","\n","        # Extract the individual dataset row (base case)\n","        individual_row = mean_df[mean_df['Combination'] == ds]\n","        if individual_row.empty:\n","            print(f'No individual data found for {ds} at {percentage}%')\n","            continue\n","\n","        # Get individual dataset statistics\n","        ind_mean_auc = individual_row['Mean_AUC'].values[0]\n","        ind_std_auc = individual_row['Std_AUC'].values[0]\n","        ind_mean_precision = individual_row['Mean_Precision'].values[0]\n","        ind_std_precision = individual_row['Std_Precision'].values[0]\n","\n","        # Filter out the combinations (excluding the individual dataset itself)\n","        combination_rows = mean_df[mean_df['Combination'] != ds]\n","\n","        # Initialize a list to store hypothesis test results\n","        hypothesis_results = []\n","\n","        for _, row in combination_rows.iterrows():\n","            combination_name = row['Combination']\n","\n","            # Get combination statistics\n","            comb_mean_auc = row['Mean_AUC']\n","            comb_std_auc = row['Std_AUC']\n","            comb_mean_precision = row['Mean_Precision']\n","            comb_std_precision = row['Std_Precision']\n","\n","            # Check for valid data\n","            if pd.isna(comb_mean_auc) or pd.isna(comb_std_auc) or pd.isna(comb_mean_precision) or pd.isna(comb_std_precision):\n","                print(f'Skipping combination {combination_name} due to NaN values at {percentage}%')\n","                continue\n","\n","            # Perform one-sided t-tests as per your specified hypotheses\n","            # Null Hypothesis: Mean individual <= Mean combined\n","            # Alternative Hypothesis: Mean individual > Mean combined\n","            # Therefore, we set alternative='greater' in ttest_ind_from_stats\n","\n","            # AUC t-test\n","            auc_t_stat, auc_p_value = stats.ttest_ind_from_stats(\n","                mean1=ind_mean_auc, std1=ind_std_auc, nobs1=num_seeds,\n","                mean2=comb_mean_auc, std2=comb_std_auc, nobs2=num_seeds,\n","                equal_var=False, alternative='greater'\n","            )\n","            # Determine decision for AUC\n","            if auc_p_value < alpha:\n","                auc_decision = 'Reject Null Hypothesis'\n","            else:\n","                auc_decision = 'Fail to Reject Null Hypothesis'\n","\n","            # Precision t-test\n","            precision_t_stat, precision_p_value = stats.ttest_ind_from_stats(\n","                mean1=ind_mean_precision, std1=ind_std_precision, nobs1=num_seeds,\n","                mean2=comb_mean_precision, std2=comb_std_precision, nobs2=num_seeds,\n","                equal_var=False, alternative='greater'\n","            )\n","            # Determine decision for Precision\n","            if precision_p_value < alpha:\n","                precision_decision = 'Reject Null Hypothesis'\n","            else:\n","                precision_decision = 'Fail to Reject Null Hypothesis'\n","\n","            # Store results\n","            result = {\n","                'Dataset': ds,\n","                'Percentage': percentage,\n","                'Combination': combination_name,\n","                'AUC_T-Statistic': auc_t_stat,\n","                'AUC_P-Value': auc_p_value,\n","                'AUC_Decision': auc_decision,\n","                'Precision_T-Statistic': precision_t_stat,\n","                'Precision_P-Value': precision_p_value,\n","                'Precision_Decision': precision_decision\n","            }\n","            hypothesis_results.append(result)\n","\n","        # Save the hypothesis test results to a CSV file\n","        if hypothesis_results:\n","            hypothesis_df = pd.DataFrame(hypothesis_results)\n","            hypothesis_save_path = os.path.join(ds_hypothesis_dir, f'hypothesis_testing_{ds}_{percentage_str}.csv')\n","            hypothesis_df.to_csv(hypothesis_save_path, index=False)\n","            print(f'Hypothesis test results saved for {ds} at {percentage}%: {hypothesis_save_path}')\n","        else:\n","            print(f'No hypothesis test results for {ds} at {percentage}%')\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Am2tGWOUjXTy","executionInfo":{"status":"ok","timestamp":1732728068487,"user_tz":480,"elapsed":1677,"user":{"displayName":"Ali Mohammadi","userId":"05142640900046941517"}},"outputId":"5f75d308-6702-4537-83c6-b52e316c45dd"},"execution_count":15,"outputs":[{"output_type":"stream","name":"stdout","text":["Hypothesis test results saved for algo004 at 0.05%: /content/drive/MyDrive/Colab Notebooks/GNN Research/hypothesis_testing/algo004/hypothesis_testing_algo004_0.05p.csv\n","Hypothesis test results saved for algo004 at 0.1%: /content/drive/MyDrive/Colab Notebooks/GNN Research/hypothesis_testing/algo004/hypothesis_testing_algo004_0.1p.csv\n","Hypothesis test results saved for algo004 at 0.15%: /content/drive/MyDrive/Colab Notebooks/GNN Research/hypothesis_testing/algo004/hypothesis_testing_algo004_0.15p.csv\n","Hypothesis test results saved for algo004 at 0.2%: /content/drive/MyDrive/Colab Notebooks/GNN Research/hypothesis_testing/algo004/hypothesis_testing_algo004_0.2p.csv\n","Hypothesis test results saved for algo004 at 0.25%: /content/drive/MyDrive/Colab Notebooks/GNN Research/hypothesis_testing/algo004/hypothesis_testing_algo004_0.25p.csv\n","Hypothesis test results saved for algo004 at 0.5%: /content/drive/MyDrive/Colab Notebooks/GNN Research/hypothesis_testing/algo004/hypothesis_testing_algo004_0.5p.csv\n","Hypothesis test results saved for algo004 at 0.75%: /content/drive/MyDrive/Colab Notebooks/GNN Research/hypothesis_testing/algo004/hypothesis_testing_algo004_0.75p.csv\n","Hypothesis test results saved for comp at 0.05%: /content/drive/MyDrive/Colab Notebooks/GNN Research/hypothesis_testing/comp/hypothesis_testing_comp_0.05p.csv\n","Hypothesis test results saved for comp at 0.1%: /content/drive/MyDrive/Colab Notebooks/GNN Research/hypothesis_testing/comp/hypothesis_testing_comp_0.1p.csv\n","Hypothesis test results saved for comp at 0.15%: /content/drive/MyDrive/Colab Notebooks/GNN Research/hypothesis_testing/comp/hypothesis_testing_comp_0.15p.csv\n","Hypothesis test results saved for comp at 0.2%: /content/drive/MyDrive/Colab Notebooks/GNN Research/hypothesis_testing/comp/hypothesis_testing_comp_0.2p.csv\n","Hypothesis test results saved for comp at 0.25%: /content/drive/MyDrive/Colab Notebooks/GNN Research/hypothesis_testing/comp/hypothesis_testing_comp_0.25p.csv\n","Hypothesis test results saved for comp at 0.5%: /content/drive/MyDrive/Colab Notebooks/GNN Research/hypothesis_testing/comp/hypothesis_testing_comp_0.5p.csv\n","Hypothesis test results saved for comp at 0.75%: /content/drive/MyDrive/Colab Notebooks/GNN Research/hypothesis_testing/comp/hypothesis_testing_comp_0.75p.csv\n","Hypothesis test results saved for ml at 0.05%: /content/drive/MyDrive/Colab Notebooks/GNN Research/hypothesis_testing/ml/hypothesis_testing_ml_0.05p.csv\n","Hypothesis test results saved for ml at 0.1%: /content/drive/MyDrive/Colab Notebooks/GNN Research/hypothesis_testing/ml/hypothesis_testing_ml_0.1p.csv\n","Hypothesis test results saved for ml at 0.15%: /content/drive/MyDrive/Colab Notebooks/GNN Research/hypothesis_testing/ml/hypothesis_testing_ml_0.15p.csv\n","Hypothesis test results saved for ml at 0.2%: /content/drive/MyDrive/Colab Notebooks/GNN Research/hypothesis_testing/ml/hypothesis_testing_ml_0.2p.csv\n","Hypothesis test results saved for ml at 0.25%: /content/drive/MyDrive/Colab Notebooks/GNN Research/hypothesis_testing/ml/hypothesis_testing_ml_0.25p.csv\n","Hypothesis test results saved for ml at 0.5%: /content/drive/MyDrive/Colab Notebooks/GNN Research/hypothesis_testing/ml/hypothesis_testing_ml_0.5p.csv\n","Hypothesis test results saved for ml at 0.75%: /content/drive/MyDrive/Colab Notebooks/GNN Research/hypothesis_testing/ml/hypothesis_testing_ml_0.75p.csv\n","Hypothesis test results saved for virtualshakespeare at 0.05%: /content/drive/MyDrive/Colab Notebooks/GNN Research/hypothesis_testing/virtualshakespeare/hypothesis_testing_virtualshakespeare_0.05p.csv\n","Hypothesis test results saved for virtualshakespeare at 0.1%: /content/drive/MyDrive/Colab Notebooks/GNN Research/hypothesis_testing/virtualshakespeare/hypothesis_testing_virtualshakespeare_0.1p.csv\n","Hypothesis test results saved for virtualshakespeare at 0.15%: /content/drive/MyDrive/Colab Notebooks/GNN Research/hypothesis_testing/virtualshakespeare/hypothesis_testing_virtualshakespeare_0.15p.csv\n","Hypothesis test results saved for virtualshakespeare at 0.2%: /content/drive/MyDrive/Colab Notebooks/GNN Research/hypothesis_testing/virtualshakespeare/hypothesis_testing_virtualshakespeare_0.2p.csv\n","Hypothesis test results saved for virtualshakespeare at 0.25%: /content/drive/MyDrive/Colab Notebooks/GNN Research/hypothesis_testing/virtualshakespeare/hypothesis_testing_virtualshakespeare_0.25p.csv\n","Hypothesis test results saved for virtualshakespeare at 0.5%: /content/drive/MyDrive/Colab Notebooks/GNN Research/hypothesis_testing/virtualshakespeare/hypothesis_testing_virtualshakespeare_0.5p.csv\n","Hypothesis test results saved for virtualshakespeare at 0.75%: /content/drive/MyDrive/Colab Notebooks/GNN Research/hypothesis_testing/virtualshakespeare/hypothesis_testing_virtualshakespeare_0.75p.csv\n"]}]}]}